{"name":"postgres","label":"PostgreSQL","type":"target","description":"For loading data into PostgreSQL","singer_name":"target-postgres","variants":[{"name":"datamill-co","maintenance_status":"active","default":false,"repo":"https://github.com/datamill-co/target-postgres","pip_url":"singer-target-postgres","dependencies":["`target-postgres` [requires](https://www.psycopg.org/docs/install.html#runtime-requirements) the [`libpq` library](https://www.postgresql.org/docs/current/libpq.html) to be available on your system. If you've installed PostgreSQL, you should already have it, but you can also install it by itself using the [`libpq-dev` package](https://pkgs.org/download/libpq-dev) on Ubuntu/Debian or the [`libpq` Homebrew formula](https://formulae.brew.sh/formula/libpq) on macOS."],"settings_group_validation":[["postgres_host","postgres_port","postgres_database","postgres_username","postgres_password","postgres_schema"]],"settings":[{"name":"postgres_host","value":"localhost"},{"name":"postgres_port","kind":"integer","value":5432},{"name":"postgres_database"},{"name":"postgres_username"},{"name":"postgres_password","kind":"password"},{"name":"postgres_schema","schema_id":true},{"name":"postgres_sslmode","value":"prefer","description":"Refer to the libpq docs for more information about SSL: https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-PARAMKEYWORDS"},{"name":"postgres_sslcert","value":"~/.postgresql/postgresql.crt","description":"Only used if a SSL request w/ a client certificate is being made"},{"name":"postgres_sslkey","value":"~/.postgresql/postgresql.key","description":"Only used if a SSL request w/ a client certificate is being made"},{"name":"postgres_sslrootcert","value":"~/.postgresql/root.crt","description":"Used for authentication of a server SSL certificate"},{"name":"postgres_sslcrl","value":"~/.postgresql/root.crl","description":"Used for authentication of a server SSL certificate"},{"name":"invalid_records_detect","kind":"boolean","value":true,"description":"Include `false` in your config to disable `target-postgres` from crashing on invalid records"},{"name":"invalid_records_threshold","kind":"integer","value":0,"description":"Include a positive value `n` in your config to allow for `target-postgres` to encounter at most `n` invalid records per stream before giving up."},{"name":"disable_collection","kind":"boolean","value":false,"description":"Include `true` in your config to disable Singer Usage Logging: https://github.com/datamill-co/target-postgres#usage-logging"},{"name":"logging_level","kind":"options","value":"INFO","options":[{"label":"Debug","value":"DEBUG"},{"label":"Info","value":"INFO"},{"label":"Warning","value":"WARNING"},{"label":"Error","value":"ERROR"},{"label":"Critical","value":"CRITICAL"}],"description":"The level for logging. Set to `DEBUG` to get things like queries executed, timing of those queries, etc."},{"name":"persist_empty_tables","kind":"boolean","value":false,"description":"Whether the Target should create tables which have no records present in Remote."},{"name":"max_batch_rows","kind":"integer","value":200000,"description":"The maximum number of rows to buffer in memory before writing to the destination table in Postgres"},{"name":"max_buffer_size","kind":"integer","value":104857600,"description":"The maximum number of bytes to buffer in memory before writing to the destination table in Postgres. Default: 100MB in bytes"},{"name":"batch_detection_threshold","kind":"integer","description":"How often, in rows received, to count the buffered rows and bytes to check if a flush is necessary. There's a slight performance penalty to checking the buffered records count or bytesize, so this controls how often this is polled in order to mitigate the penalty. This value is usually not necessary to set as the default is dynamically adjusted to check reasonably often."},{"name":"state_support","kind":"boolean","value":true,"description":"Whether the Target should emit `STATE` messages to stdout for further consumption. In this mode, which is on by default, STATE messages are buffered in memory until all the records that occurred before them are flushed according to the batch flushing schedule the target is configured with."},{"name":"add_upsert_indexes","kind":"boolean","value":true,"description":"Whether the Target should create column indexes on the important columns used during data loading. These indexes will make data loading slightly slower but the deduplication phase much faster. Defaults to on for better baseline performance."},{"name":"before_run_sql","description":"Raw SQL statement(s) to execute as soon as the connection to Postgres is opened by the target. Useful for setup like `SET ROLE` or other connection state that is important."},{"name":"after_run_sql","description":"Raw SQL statement(s) to execute as soon as the connection to Postgres is opened by the target. Useful for setup like `SET ROLE` or other connection state that is important."}],"maintainer":{"label":"Data Mill","url":"https://datamill.co/","plugins":[{"url":"/taps/autodesk-bim-360--datamill-co","logo_url":"/assets/logos/taps/autodesk-bim-360.png","label":"AutoDesk Forge BIM 360"},{"url":"/taps/dynamics--datamill-co","logo_url":"/assets/logos/taps/dynamics.png","label":"Dynamics"},{"url":"/taps/eloqua--datamill-co","logo_url":"/assets/logos/taps/eloqua.png","label":"Eloqua"},{"url":"/targets/postgres--datamill-co","logo_url":"/assets/logos/targets/postgres.png","label":"PostgreSQL"},{"url":"/targets/snowflake--datamill-co","logo_url":"/assets/logos/targets/snowflake.png","label":"Snowflake"}],"page_url":"/singer/maintainers/datamill-co"},"metrics":{"CREATED_AT_TIMESTAMP":"2018-03-09 03:34:12 +0000","NUM_OPEN_ISSUES":27,"NUM_FORKS":59,"LAST_PUSH_TIMESTAMP":"2021-12-28 15:29:56 +0000","LAST_UPDATED_TIMESTAMP":"2021-12-22 16:51:15 +0000","NUM_STARGAZERS":85,"MELTANO_PROJECT_ID_COUNT_3M":919,"NUM_WATCHERS":85,"MELTANO_EXEC_COUNT_3M":303069},"url":"/targets/postgres--datamill-co"},{"name":"transferwise","default":true,"docs":"https://transferwise.github.io/pipelinewise/connectors/targets/postgres.html","repo":"https://github.com/transferwise/pipelinewise-target-postgres","maintenance_status":"active","pip_url":"pipelinewise-target-postgres","settings_group_validation":[["host","port","user","password","dbname","default_target_schema"]],"settings":[{"name":"host","value":"localhost","description":"PostgreSQL host","label":"Host"},{"name":"port","kind":"integer","value":5432,"description":"PostgreSQL port","label":"Port"},{"name":"user","description":"PostgreSQL user","label":"User"},{"name":"password","kind":"password","description":"PostgreSQL password","label":"Password"},{"name":"dbname","description":"PostgreSQL database name","label":"Dbname"},{"name":"ssl","kind":"boolean","value":false,"label":"Ssl"},{"name":"default_target_schema","description":"Name of the schema where the tables will be created. If `schema_mapping` is not defined then every stream sent by the tap is loaded into this schema.","label":"Default Target Schema"},{"name":"batch_size_rows","kind":"integer","value":100000,"description":"Maximum number of rows in each batch. At the end of each batch, the rows in the batch are loaded into Postgres.","label":"Batch Size Rows"},{"name":"flush_all_streams","kind":"boolean","value":false,"description":"Flush and load every stream into Postgres when one batch is full. Warning: This may trigger the COPY command to use files with low number of records.","label":"Flush All Streams"},{"name":"parallelism","kind":"integer","value":0,"description":"The number of threads used to flush tables. 0 will create a thread for each stream, up to parallelism_max. -1 will create a thread for each CPU core. Any other positive number will create that number of threads, up to parallelism_max.","label":"Parallelism"},{"name":"parallelism_max","kind":"integer","value":16,"description":"Max number of parallel threads to use when flushing tables.","label":"Parallelism Max"},{"name":"default_target_schema_select_permission","description":"Grant USAGE privilege on newly created schemas and grant SELECT privilege on newly created tables to a specific role or a list of roles. If `schema_mapping` is not defined then every stream sent by the tap is granted accordingly.","label":"Default Target Schema Select Permission"},{"name":"schema_mapping","kind":"object","description":"Useful if you want to load multiple streams from one tap to multiple Postgres schemas. If the tap sends the `stream_id` in `<schema_name>-<table_name>` format then this option overwrites the `default_target_schema` value. Note, that using `schema_mapping` you can overwrite the `default_target_schema_select_permission` value to grant SELECT permissions to different groups per schemas or optionally you can create indices automatically for the replicated tables.\n","label":"Schema Mapping"},{"name":"add_metadata_columns","kind":"boolean","value":false,"description":"Metadata columns add extra row level information about data ingestions, (i.e. when was the row read in source, when was inserted or deleted in postgres etc.) Metadata columns are creating automatically by adding extra columns to the tables with a column prefix `_SDC_`. The column names are following the stitch naming conventions documented at https://www.stitchdata.com/docs/data-structure/integration-schemas#sdc-columns. Enabling metadata columns will flag the deleted rows by setting the `_SDC_DELETED_AT` metadata column. Without the `add_metadata_columns` option the deleted rows from singer taps will not be recongisable in Postgres.","label":"Add Metadata Columns"},{"name":"hard_delete","kind":"boolean","value":false,"description":"When `hard_delete` option is true then DELETE SQL commands will be performed in Postgres to delete rows in tables. It's achieved by continuously checking the `_SDC_DELETED_AT` metadata column sent by the singer tap. Due to deleting rows requires metadata columns, `hard_delete` option automatically enables the `add_metadata_columns` option as well.","label":"Hard Delete"},{"name":"data_flattening_max_level","kind":"integer","value":0,"description":"Object type RECORD items from taps can be transformed to flattened columns by creating columns automatically. When value is 0 (default) then flattening functionality is turned off.","label":"Data Flattening Max Level"},{"name":"primary_key_required","kind":"boolean","value":true,"description":"Log based and Incremental replications on tables with no Primary Key cause duplicates when merging UPDATE events. When set to true, stop loading data if no Primary Key is defined.","label":"Primary Key Required"},{"name":"validate_records","kind":"boolean","value":false,"description":"Validate every single record message to the corresponding JSON schema. This option is disabled by default and invalid RECORD messages will fail only at load time by Postgres. Enabling this option will detect invalid records earlier but could cause performance degradation.","label":"Validate Records"},{"name":"temp_dir","description":"(Default: platform-dependent) Directory of temporary CSV files with RECORD messages.","label":"Temp Dir"}],"maintainer":{"label":"Wise","url":"https://wise.com/","plugins":[{"url":"/taps/kafka--transferwise","logo_url":"/assets/logos/taps/kafka.png","label":"Apache Kafka"},{"url":"/taps/s3-csv--transferwise","logo_url":"/assets/logos/taps/s3-csv.png","label":"AWS S3 CSV"},{"url":"/targets/bigquery--transferwise","logo_url":"/assets/logos/targets/bigquery.png","label":"BigQuery"},{"url":"/taps/google-analytics--transferwise","logo_url":"/assets/logos/taps/google-analytics.png","label":"Google Analytics"},{"url":"/taps/mixpanel--transferwise","logo_url":"/assets/logos/taps/mixpanel.png","label":"Mixpanel"},{"url":"/taps/mongodb--transferwise","logo_url":"/assets/logos/taps/mongodb.png","label":"MongoDB"},{"url":"/taps/mysql--transferwise","logo_url":"/assets/logos/taps/mysql.png","label":"MySQL / MariaDB"},{"url":"/taps/oracle--transferwise","logo_url":"/assets/logos/taps/oracle.png","label":"Oracle DB"},{"url":"/taps/postgres--transferwise","logo_url":"/assets/logos/taps/postgres.png","label":"PostgreSQL"},{"url":"/targets/postgres--transferwise","logo_url":"/assets/logos/targets/postgres.png","label":"PostgreSQL"},{"url":"/targets/redshift--transferwise","logo_url":"/assets/logos/targets/redshift.png","label":"Redshift"},{"url":"/taps/salesforce--transferwise","logo_url":"/assets/logos/taps/salesforce.png","label":"Salesforce"},{"url":"/taps/slack--transferwise","logo_url":"/assets/logos/taps/slack.png","label":"Slack"},{"url":"/targets/snowflake--transferwise","logo_url":"/assets/logos/targets/snowflake.png","label":"Snowflake"},{"url":"/taps/snowflake--transferwise","logo_url":"/assets/logos/taps/snowflake.png","label":"Snowflake"},{"url":"/taps/twilio--transferwise","logo_url":"/assets/logos/taps/twilio.png","label":"Twilio"},{"url":"/taps/zendesk--transferwise","logo_url":"/assets/logos/taps/zendesk.png","label":"Zendesk"},{"url":"/taps/zuora--transferwise","logo_url":"/assets/logos/taps/zuora.png","label":"Zuora"}],"page_url":"/singer/maintainers/transferwise"},"metrics":{"CREATED_AT_TIMESTAMP":"2019-06-02 15:10:19 +0000","NUM_OPEN_ISSUES":14,"NUM_FORKS":16,"LAST_PUSH_TIMESTAMP":"2022-02-14 21:04:13 +0000","LAST_UPDATED_TIMESTAMP":"2022-02-17 22:29:19 +0000","NUM_STARGAZERS":11,"MELTANO_PROJECT_ID_COUNT_3M":0,"NUM_WATCHERS":11,"MELTANO_EXEC_COUNT_3M":0},"url":"/targets/postgres--transferwise"},{"name":"meltano","repo":"https://github.com/meltano/target-postgres","maintenance_status":"active","pip_url":"git+https://github.com/meltano/target-postgres.git","settings_group_validation":[["url","schema"],["user","password","host","port","dbname","schema"]],"settings":[{"name":"user","value":"warehouse"},{"name":"password","kind":"password","value":"warehouse"},{"name":"host","value":"localhost"},{"name":"port","kind":"integer","value":5502},{"name":"dbname","label":"Database Name","value":"warehouse"},{"name":"url","label":"URL","description":"Lets you set `user`, `password`, `host`, `port`, and `dbname` in one go using a `postgresql://` URI. Takes precedence over the other settings when set."},{"name":"schema","schema_id":true}],"maintainer":{"label":"Meltano Community","url":"https://meltano.com/","plugins":[{"url":"/taps/carbon-intensity--meltano","logo_url":"/assets/logos/taps/carbon-intensity.png","label":"Carbon Emissions Intensity"},{"url":"/taps/csv--meltano","logo_url":"/assets/logos/taps/csv.png","label":"CSV"},{"url":"/taps/facebook--meltano","logo_url":"/assets/logos/taps/facebook.png","label":"Facebook Ads"},{"url":"/taps/fastly--meltano","logo_url":"/assets/logos/taps/fastly.png","label":"Fastly"},{"url":"/taps/gitlab--meltano","logo_url":"/assets/logos/taps/gitlab.png","label":"GitLab"},{"url":"/taps/adwords--meltano","logo_url":"/assets/logos/taps/adwords.png","label":"Google Ads"},{"url":"/taps/google-analytics--meltano","logo_url":"/assets/logos/taps/google-analytics.png","label":"Google Analytics"},{"url":"/taps/marketo--meltano","logo_url":"/assets/logos/taps/marketo.png","label":"Marketo"},{"url":"/targets/postgres--meltano","logo_url":"/assets/logos/targets/postgres.png","label":"PostgreSQL"},{"url":"/taps/salesforce--meltano","logo_url":"/assets/logos/taps/salesforce.png","label":"Salesforce"},{"url":"/targets/snowflake--meltano","logo_url":"/assets/logos/targets/snowflake.png","label":"Snowflake"},{"url":"/targets/sqlite--meltano","logo_url":"/assets/logos/targets/sqlite.png","label":"SQLite"},{"url":"/taps/stripe--meltano","logo_url":"/assets/logos/taps/stripe.png","label":"Stripe"}],"page_url":"/singer/maintainers/meltano"},"metrics":{"CREATED_AT_TIMESTAMP":"2018-09-26 19:37:20 +0000","NUM_OPEN_ISSUES":3,"NUM_FORKS":8,"LAST_PUSH_TIMESTAMP":"2021-01-19 22:34:03 +0000","LAST_UPDATED_TIMESTAMP":"2021-03-24 14:38:31 +0000","NUM_STARGAZERS":2,"MELTANO_PROJECT_ID_COUNT_3M":919,"NUM_WATCHERS":2,"MELTANO_EXEC_COUNT_3M":303069},"url":"/targets/postgres--meltano"}],"entity_url":"https://www.postgresql.org/","entity_type":"database","logo_url":"/assets/logos/targets/postgres.png","meltano_url":"/loaders/postgres","url":"/targets/postgres"}