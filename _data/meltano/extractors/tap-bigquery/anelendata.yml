name: tap-bigquery
label: BigQuery
description: BigQuery data warehouse extractor
namespace: tap_bigquery
logo_url: /assets/logos/extractors/bigquery.png
variant: anelendata
repo: https://github.com/anelendata/tap-bigquery
pip_url: tap-bigquery
capabilities:
- catalog
- discover
- state
settings_group_validation:
- - streams
  - start_datetime
  - credentials_path
prereq: |
  Additionally you should follow the steps in the ["Activate the Google BigQuery API" section](https://github.com/anelendata/tap-bigquery#step-1-activate-the-google-bigquery-api) of the repository's README.
settings:
- name: streams
  label: Streams
  kind: array
  description: |
    Array of objects with `name`, `table`, `columns`, `datetime_key`, and `filters` keys:

    - `name`: The entity name, used by most loaders as the name of the table to be created.
    - `table`: Fully qualified table name in BigQuery, with format `` `<project>.<dataset>.<table>` ``. Since backticks have special meaning in YAML, values in `meltano.yml` should be wrapped in double quotes.
    - `columns`: Array of column names to select. Using `["*"]` is not recommended as it can become very expensive for a table with a large number of columns.
    - `datetime_key`: Name of datetime column to use as [replication key](https://docs.meltano.com/integration.html#replication-key).
    - `filters`: Optional array of `WHERE` clauses to filter extracted data, e.g. `"column='value'"`.
- name: credentials_path
  label: Credentials Path
  value: $MELTANO_PROJECT_ROOT/client_secrets.json
  description: |
    Fully qualified path to `client_secrets.json` for your service account.

    See the ["Activate the Google BigQuery API" section of the repository's README](https://github.com/anelendata/tap-bigquery#step-1-activate-the-google-bigquery-api) and <https://cloud.google.com/docs/authentication/production>.

    By default, this file is expected to be at the root of your project directory.
- name: start_datetime
  label: Start Datetime
  kind: date_iso8601
  description: Determines how much historical data will be extracted. Please be aware
    that the larger the time period and amount of data, the longer the initial extraction
    can be expected to take.
- name: end_datetime
  label: End Datetime
  kind: date_iso8601
  description: Date up to when historical data will be extracted.
- name: limit
  label: Limit
  kind: integer
  description: Limits the number of records returned in each stream, applied as a
    limit in the query.
- name: start_always_inclusive
  label: Start Always Inclusive
  kind: boolean
  value: true
  description: When replicating incrementally, disable to only select records whose
    `datetime_key` is greater than the maximum value replicated in the last run, by
    excluding records whose timestamps match exactly. This could cause records to
    be missed that were created after the last run finished, but during the same second
    and with the same timestamp.
domain_url: https://cloud.google.com/bigquery
maintenance_status: active
keywords:
- database
