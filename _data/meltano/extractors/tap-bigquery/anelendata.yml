capabilities:
- catalog
- discover
- state
description: BigQuery data warehouse extractor
domain_url: https://cloud.google.com/bigquery
keywords:
- database
label: BigQuery
logo_url: /assets/logos/extractors/bigquery.png
maintenance_status: active
name: tap-bigquery
namespace: tap_bigquery
pip_url: tap-bigquery
prereq: |
  Additionally you should follow the steps in the ["Activate the Google BigQuery API" section](https://github.com/anelendata/tap-bigquery#step-1-activate-the-google-bigquery-api) of the repository's README.
repo: https://github.com/anelendata/tap-bigquery
settings:
- description: |
    Array of objects with `name`, `table`, `columns`, `datetime_key`, and `filters` keys:

    - `name`: The entity name, used by most loaders as the name of the table to be created.
    - `table`: Fully qualified table name in BigQuery, with format `` `<project>.<dataset>.<table>` ``. Since backticks have special meaning in YAML, values in `meltano.yml` should be wrapped in double quotes.
    - `columns`: Array of column names to select. Using `["*"]` is not recommended as it can become very expensive for a table with a large number of columns.
    - `datetime_key`: Name of datetime column to use as [replication key](https://docs.meltano.com/guide/integration#replication-key).
    - `filters`: Optional array of `WHERE` clauses to filter extracted data, e.g. `"column='value'"`.
  kind: array
  label: Streams
  name: streams
- description: |
    Fully qualified path to `client_secrets.json` for your service account.

    See the ["Activate the Google BigQuery API" section of the repository's README](https://github.com/anelendata/tap-bigquery#step-1-activate-the-google-bigquery-api) and <https://cloud.google.com/docs/authentication/production>.

    By default, this file is expected to be at the root of your project directory.
  env: GOOGLE_APPLICATION_CREDENTIALS
  label: Credentials Path
  name: credentials_path
  value: $MELTANO_PROJECT_ROOT/client_secrets.json
- description: Determines how much historical data will be extracted. Please be aware
    that the larger the time period and amount of data, the longer the initial extraction
    can be expected to take.
  kind: date_iso8601
  label: Start Datetime
  name: start_datetime
- description: Date up to when historical data will be extracted.
  kind: date_iso8601
  label: End Datetime
  name: end_datetime
- description: Limits the number of records returned in each stream, applied as a
    limit in the query.
  kind: integer
  label: Limit
  name: limit
- description: When replicating incrementally, disable to only select records whose
    `datetime_key` is greater than the maximum value replicated in the last run, by
    excluding records whose timestamps match exactly. This could cause records to
    be missed that were created after the last run finished, but during the same second
    and with the same timestamp.
  kind: boolean
  label: Start Always Inclusive
  name: start_always_inclusive
  value: true
settings_group_validation:
- - streams
  - start_datetime
  - credentials_path
variant: anelendata
