dashboards:
- name: dashboard-google-analytics
  namespace: tap_google_analytics
  pip_url: git+https://gitlab.com/meltano/dashboard-google-analytics.git
  repo: https://gitlab.com/meltano/dashboard-google-analytics
  variant: meltano
- name: dashboard-stripe
  namespace: tap_stripe
  pip_url: git+https://gitlab.com/meltano/dashboard-stripe.git
  repo: https://gitlab.com/meltano/dashboard-stripe
  variant: meltano
- name: dashboard-facebook
  namespace: tap_facebook
  pip_url: git+https://gitlab.com/meltano/dashboard-facebook.git
  repo: https://gitlab.com/meltano/dashboard-facebook
  variant: meltano
- name: dashboard-adwords
  namespace: tap_adwords
  pip_url: git+https://gitlab.com/meltano/dashboard-adwords.git
  repo: https://gitlab.com/meltano/dashboard-adwords
  variant: meltano
- name: dashboard-shopify
  namespace: tap_shopify
  pip_url: git+https://gitlab.com/meltano/dashboard-shopify.git
  repo: https://gitlab.com/meltano/dashboard-shopify
  variant: meltano
- name: dashboard-gitlab
  namespace: tap_gitlab
  pip_url: git+https://gitlab.com/meltano/dashboard-gitlab.git
  repo: https://gitlab.com/meltano/dashboard-gitlab
  variant: meltano
extractors:
- description: Subscription billing software
  label: Chargebee
  name: tap-chargebee
  namespace: tap_chargebee
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/chargebee.html
    name: hotgluexyz
    pip_url: git+https://github.com/hotgluexyz/tap-chargebee.git
    repo: https://github.com/hotgluexyz/tap-chargebee
    settings:
    - kind: password
      label: API Key
      name: api_key
    - label: Chargebee Site
      name: site
    - label: Chargebee Product Catalog
      name: product_catalog
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    - description: Select by default any new fields discovered in Quickbooks objects
      kind: boolean
      name: select_fields_by_default
      value: true
    - description: Generate a STATE message every N records
      kind: integer
      name: state_message_threshold
      value: 1000
    - kind: integer
      label: Maximum number of threads to use
      name: max_workers
      value: 8
    settings_group_validation:
    - - api_key
      - site
      - product_catalog
      - start_date
- description: Online payment processing for internet businesses
  label: Stripe
  name: tap-stripe
  namespace: tap_stripe
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/stripe.html
    name: meltano
    pip_url: git+https://github.com/meltano/tap-stripe.git
    repo: https://github.com/meltano/tap-stripe
    settings:
    - env_aliases:
      - STRIPE_ACCOUNT_ID
      label: Account ID
      name: account_id
      placeholder: Ex. acct_1a2b3c4d5e
    - env_aliases:
      - STRIPE_API_KEY
      kind: password
      label: Secret API Key
      name: client_secret
      placeholder: Ex. sk_live_1a2b3c4d5e
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
- description: Cloud Spreadsheets
  label: Google Sheets
  name: tap-google-sheets
  namespace: tap_google_sheets
  variants:
  - capabilities:
    - discover
    - catalog
    - state
    docs: https://hub.meltano.com/extractors/google-sheets
    name: singer-io
    pip_url: git+https://github.com/singer-io/tap-google-sheets.git
    repo: https://github.com/singer-io/tap-google-sheets
    settings:
    - description: This is the ID setup via the Google Cloud API.
      documentation: https://drive.google.com/open?id=1FojlvtLwS0-BzGS37R0jEXtwSHqSiO1Uw-7RKQQO-C4
      label: Client ID
      name: client_id
    - description: This is generated when the client ID is created via the Google
        Cloud API.
      documentation: https://drive.google.com/open?id=1FojlvtLwS0-BzGS37R0jEXtwSHqSiO1Uw-7RKQQO-C4
      kind: password
      label: Client Secret
      name: client_secret
    - description: This is the token used to generate new access_tokens. It is manually
        generated by making an API call to the Google Cloud API. See the [documentation](https://drive.google.com/open?id=1FojlvtLwS0-BzGS37R0jEXtwSHqSiO1Uw-7RKQQO-C4)
        for more information.
      documentation: https://drive.google.com/open?id=1FojlvtLwS0-BzGS37R0jEXtwSHqSiO1Uw-7RKQQO-C4
      kind: password
      label: Refresh Token
      name: refresh_token
    - description: The unique identifier for a spreadsheet.
      label: Spreadsheet ID
      name: spreadsheet_id
    - description: The absolute minimum start date to check if a file was modified.
      kind: date_iso8601
      label: Start Date
      name: start_date
      placeholder: Ex. "2019-01-01T00:00:00Z"
    - description: Used to identify the tap in the Google Remote API logs.
      label: User Agent
      name: user_agent
      placeholder: Ex. "tap-google-search-console <api_user_email@example.com>"
      value: tap-google-sheets via Meltano
    settings_group_validation:
    - - client_id
      - client_secret
      - refresh_token
      - spreadsheet_id
      - start_date
      - user_agent
- description: Advertising Platform
  label: Facebook Ads
  name: tap-facebook
  namespace: tap_facebook
  variants:
  - capabilities:
    - properties
    - discover
    - state
    docs: https://hub.meltano.com/extractors/facebook.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-facebook.git
    repo: https://gitlab.com/meltano/tap-facebook
    settings:
    - description: Your Facebook Ads Account ID
      label: Account ID
      name: account_id
      placeholder: Ex. 123456789012345
    - description: User Token generated by Facebook OAuth handshake
      kind: oauth
      label: Access Token
      name: access_token
      oauth:
        provider: facebook
      placeholder: Ex. *****************
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    - description: Date up to when historical data will be extracted.
      kind: date_iso8601
      name: end_date
    - description: How many Days before the Start Date to fetch Ads Insights for
      kind: integer
      label: Ads Insights Buffer Days
      name: insights_buffer_days
      value: 0
    settings_group_validation:
    - - account_id
      - access_token
      - start_date
- description: Product Experience and Digital Adoption Solutions
  label: Pendo
  name: tap-pendo
  namespace: tap_pendo
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/pendo
    name: singer-io
    pip_url: git+https://github.com/singer-io/tap-pendo.git
    repo: https://github.com/singer-io/tap-pendo
    settings:
    - description: 'This is the integration key generated via the Pendo website: Settings
        -> Integrations -> Integration Keys.'
      env: TAP_PENDO_INTEGRATION_KEY
      kind: password
      label: Integration Key
      name: x_pendo_integration_key
    - description: This defines how data is aggregated, either on a daily or hourly
        basis.
      kind: options
      label: Period
      name: period
      options:
      - label: Daily
        value: dayRange
      - label: Hourly
        value: hourRange
    - description: The number of days to use as the lookback window.
      kind: integer
      label: Lookback Window
      name: lookback_window
      value: 0
    - default: false
      description: Defines whether or not to include anonymous visitors in the results.
      kind: boolean
      label: Include Anonymous Visitors
      name: include_anonymous_visitors
      value_post_processor: stringify
    - description: This is the default start date value to use if no bookmark is present.
      kind: date_iso8601
      label: Start Date
      name: start_date
    settings_group_validation:
    - - x_pendo_integration_key
      - period
      - start_date
- description: Generic data extractor of CSV (comma separated value) files
  label: Comma Separated Values (CSV)
  name: tap-csv
  namespace: tap_csv
  variants:
  - capabilities:
    - discover
    - state
    docs: https://hub.meltano.com/extractors/csv.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-csv.git
    repo: https://gitlab.com/meltano/tap-csv
    settings:
    - description: Array of objects with `entity`, `file`, and `keys` keys
      kind: array
      name: files
    - description: Project-relative path to JSON file holding array of objects with
        `entity`, `file`, and `keys` keys
      documentation: https://gitlab.com/meltano/tap-csv#run
      env: TAP_CSV_FILES_DEFINITION
      label: CSV Files Definition
      name: csv_files_definition
      placeholder: Ex. files-def.json
    settings_group_validation:
    - - files
    - - csv_files_definition
- description: Cloud communications platform as a service
  label: Twilio
  name: tap-twilio
  namespace: tap_twilio
  variants:
  - capabilities:
    - discover
    - catalog
    - state
    docs: https://hub.meltano.com/extractors/twilio
    name: transferwise
    pip_url: git+https://github.com/transferwise/pipelinewise-tap-twilio.git
    repo: https://github.com/transferwise/pipelinewise-tap-twilio
    settings:
    - description: This is the String ID of your account which can be found in the
        account console at twilio.com/console.
      label: Account String ID
      name: account_sid
    - description: This is the authorization token for your account which can be found
        in the account console at twilio.com/console.
      kind: password
      label: Auth Token
      name: auth_token
    - description: This is the integer number of days (between the from and to dates)
        for date-windowing through the date-filtered endpoints.
      kind: integer
      label: Date Window Days
      name: date_window_days
      value: 30
    - description: This is the absolute beginning date from which incremental loading
        on the initial load will start
      kind: date_iso8601
      label: Start Date
      name: start_date
    - description: This is used to identify the process running the tap.
      label: User Agent
      name: user_agent
      placeholder: Ex. "tap-twilio <api_user_email@your_company.com>"
      value: tap-twilio via Meltano
    settings_group_validation:
    - - account_sid
      - auth_token
      - start_date
      - user_agent
- description: General purpose, document-based, distributed database
  label: MongoDB
  name: tap-mongodb
  namespace: tap_mongodb
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/mongodb.html
    name: singer-io
    pip_url: tap-mongodb
    repo: https://github.com/singer-io/tap-mongodb
    settings:
    - label: Host URL
      name: host
      value: localhost
    - kind: integer
      name: port
      value: 27017
    - name: user
    - kind: password
      name: password
    - label: Database Name
      name: database
    - name: replica_set
    - kind: boolean
      label: SSL
      name: ssl
      value: false
      value_post_processor: stringify
    - description: SSL Verify Mode
      kind: boolean
      name: verify_mode
      value: true
      value_post_processor: stringify
    - description: Forces the stream names to take the form `<database_name>_<collection_name>`
        instead of `<collection_name>`
      kind: boolean
      name: include_schemas_in_destination_stream_name
      value: false
    settings_group_validation:
    - - host
      - port
      - user
      - password
      - database
- description: MySQL / MariaDB database extractor
  label: MySQL / MariaDB
  name: tap-mysql
  namespace: tap_mysql
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/mysql.html
    name: transferwise
    pip_url: pipelinewise-tap-mysql
    repo: https://github.com/transferwise/pipelinewise-tap-mysql
    settings:
    - name: host
      value: localhost
    - kind: integer
      name: port
      value: 3306
    - name: user
    - kind: password
      name: password
    - name: database
    - kind: boolean
      name: ssl
      value: false
      value_post_processor: stringify
    - description: Comma separated list of schemas to extract tables only from particular
        schemas and to improve data extraction performance
      name: filter_dbs
    - description: List of SQL commands to run when a connection made. This allows
        to set session variables dynamically, like timeouts.
      kind: array
      name: session_sqls
      value:
      - SET @@session.time_zone="+0:00"
      - SET @@session.wait_timeout=28800
      - SET @@session.net_read_timeout=3600
      - SET @@session.innodb_lock_wait_timeout=3600
    settings_group_validation:
    - - host
      - port
      - user
      - password
- description: Team communication tool
  label: Slack
  name: tap-slack
  namespace: tap_slack
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/slack.html
    name: mashey
    pip_url: git+https://github.com/Mashey/tap-slack.git
    repo: https://github.com/Mashey/tap-slack
    settings:
    - documentation: https://slack.com/help/articles/215770388-Create-and-regenerate-API-tokens
      kind: password
      label: API Token
      name: api_token
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      label: Sync Start Date
      name: start_date
    - description: By default the tap will sync all channels it has been invited to,
        but this can be overriden to limit it ot specific channels. Note this needs
        to be channel ID, not the name, as recommended by the Slack API. To get the
        ID for a channel, either use the Slack API or find it in the URL.
      kind: array
      labels: Channels to Sync
      name: channels
      placeholder: Ex. ["abc123", "def456"]
    - description: Specifies whether to sync private channels or not. Default is true.
      kind: boolean
      label: Join Private Channels
      name: private_channels
      value: true
    - description: Specifies whether to have the tap auto-join all public channels
        in your ogranziation. Default is false.
      kind: boolean
      label: Join Public Channels
      name: join_public_channels
      value: false
    - description: Specifies whether the tap will sync archived channels or not. Note
        that a bot cannot join an archived channel, so unless the bot was added to
        the channel prior to it being archived it will not be able to sync the data
        from that channel. Default is false.
      kind: boolean
      label: Sync Archived Channels
      name: archived_channels
      value: false
    - description: Specifies the window size for syncing certain streams (messages,
        files, threads). The default is 7 days.
      kind: integer
      label: Date Window Size
      name: date_window_size
      value: 7
- description: BigQuery data warehouse extractor
  label: BigQuery
  name: tap-bigquery
  namespace: tap_bigquery
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/bigquery.html
    name: anelendata
    pip_url: tap-bigquery
    repo: https://github.com/anelendata/tap-bigquery
    settings:
    - description: Array holding objects describing streams (tables) to extract, with
        `name`, `table`, `columns`, `datetime_key`, and `filters` keys. See docs for
        details.
      kind: array
      name: streams
    - description: Fully qualified path to `client_secrets.json` for your service
        account.
      env_aliases:
      - GOOGLE_APPLICATION_CREDENTIALS
      name: credentials_path
      value: $MELTANO_PROJECT_ROOT/client_secrets.json
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_datetime
    - description: Date up to when historical data will be extracted.
      kind: date_iso8601
      name: end_datetime
    - description: Limits the number of records returned in each stream, applied as
        a limit in the query.
      kind: integer
      name: limit
    - description: When replicating incrementally, disable to only select records
        whose `datetime_key` is greater than the maximum value replicated in the last
        run, by excluding records whose timestamps match exactly. This could cause
        records to be missed that were created after the last run finished, but during
        the same second and with the same timestamp.
      kind: boolean
      name: start_always_inclusive
      value: true
    settings_group_validation:
    - - streams
      - start_datetime
      - credentials_path
- description: Marketing automation for account-based marketing
  label: Marketo
  name: tap-marketo
  namespace: tap_marketo
  variants:
  - capabilities: []
    docs: https://hub.meltano.com/extractors/marketo.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-marketo.git
    repo: https://gitlab.com/meltano/tap-marketo
    settings:
    - name: endpoint
    - name: identity
    - label: Client ID
      name: client_id
    - kind: password
      name: client_secret
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
- description: App and website analytics platform hosted by Google
  label: Google Analytics
  name: tap-google-analytics
  namespace: tap_google_analytics
  variants:
  - capabilities:
    - catalog
    - discover
    docs: https://hub.meltano.com/extractors/google-analytics.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-google-analytics.git
    repo: https://gitlab.com/meltano/tap-google-analytics
    settings:
    - env_aliases:
      - GOOGLE_ANALYTICS_API_CLIENT_SECRETS
      kind: file
      label: Client Secrets
      name: key_file_location
      placeholder: Ex. client_secrets.json
      value: $MELTANO_PROJECT_ROOT/client_secrets.json
    - env_aliases:
      - GOOGLE_ANALYTICS_API_OAUTH_CLIENT_ID
      kind: password
      label: OAuth Client ID
      name: oauth_credentials.client_id
    - env_aliases:
      - GOOGLE_ANALYTICS_API_OAUTH_CLIENT_SECRET
      kind: password
      label: OAuth Client Secret
      name: oauth_credentials.client_secret
    - env_aliases:
      - GOOGLE_ANALYTICS_API_OAUTH_ACCESS_TOKEN
      kind: password
      label: OAuth Access Token
      name: oauth_credentials.access_token
    - env_aliases:
      - GOOGLE_ANALYTICS_API_OAUTH_REFRESH_TOKEN
      kind: password
      label: OAuth Refresh Token
      name: oauth_credentials.refresh_token
    - env_aliases:
      - GOOGLE_ANALYTICS_API_VIEW_ID
      label: View ID
      name: view_id
      placeholder: Ex. 198343027
    - env_aliases:
      - GOOGLE_ANALYTICS_API_REPORTS
      label: Reports
      name: reports
      placeholder: Ex. my_report_definition.json
    - description: This property determines how much historical data will be extracted.
        Please be aware that the larger the time period and amount of data, the longer
        the initial extraction can be expected to take.
      env_aliases:
      - GOOGLE_ANALYTICS_API_START_DATE
      kind: date_iso8601
      name: start_date
    - description: Date up to when historical data will be extracted.
      env_aliases:
      - GOOGLE_ANALYTICS_API_END_DATE
      kind: date_iso8601
      name: end_date
    settings_group_validation:
    - - key_file_location
      - view_id
      - start_date
    - - oauth_credentials.client_id
      - oauth_credentials.client_secret
      - oauth_credentials.access_token
      - oauth_credentials.refresh_token
      - view_id
      - start_date
- description: Inbound Marketing software
  label: Hubspot
  name: tap-hubspot
  namespace: tap_hubspot
  variants:
  - capabilities:
    - discover
    - properties
    - state
    docs: https://hub.meltano.com/extractors/hubspot
    name: singer-io
    pip_url: git+https://github.com/singer-io/tap-hubspot.git
    repo: https://github.com/singer-io/tap-hubspot
    settings:
    - description: This is the URL that the user will be redirected to after they
        authorize your app for the requested scopes
      documentation: https://legacydocs.hubspot.com/docs/methods/oauth2/oauth2-quickstart
      label: Redirect URI
      name: redirect_uri
    - description: This identifies the app used to connect to HubSpot.
      documentation: https://legacydocs.hubspot.com/docs/methods/oauth2/oauth2-quickstart
      label: Client ID
      name: client_id
    - description: The client secret used for authentication.
      kind: password
      label: Client Secret
      name: client_secret
    - description: This is the refresh token provided by HubSpot.
      kind: password
      label: Refresh Token
      name: refresh_token
    - description: This is the cutoff date for syncing historical data.
      kind: date_iso8601
      label: Start Date
      name: start_date
    settings_group_validation:
    - - redirect_uri
      - client_id
      - client_secret
      - refresh_token
      - start_date
- description: Code hosting platform
  label: GitHub
  name: tap-github
  namespace: tap_github
  variants:
  - capabilities:
    - properties
    - discover
    - state
    docs: https://hub.meltano.com/extractors/github
    name: singer-io
    pip_url: git+https://github.com/singer-io/tap-github.git
    repo: https://github.com/singer-io/tap-github
    settings:
    - description: Personal access token used to authenticate with GitHub. The token
        can be generated by going to the [Personal Access Token settings page](https://github.com/settings/tokens).
      docs: https://github.com/settings/tokens
      kind: password
      label: Personal Access Tokens
      name: access_token
    - description: Space-separated list of repositories. Each repository must be prefaced
        by the user/organization name, e.g. `"meltano/meltano meltano/sdk meltano/hub"`
      label: Repositories
      name: repository
      placeholder: Ex. "meltano/meltano meltano/sdk meltano/hub"
    - description: Defines how far into the past to pull data for the provided repositories.
      kind: date_iso8601
      label: Start Date
      name: start_date
    settings_group_validation:
    - - access_token
      - repository
      - start_date
- description: PostgreSQL database extractor
  label: PostgreSQL
  name: tap-postgres
  namespace: tap_postgres
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/postgres.html
    name: transferwise
    pip_url: pipelinewise-tap-postgres
    repo: https://github.com/transferwise/pipelinewise-tap-postgres
    settings:
    - description: PostgreSQL host
      name: host
      value: localhost
    - description: PostgreSQL port
      kind: integer
      name: port
      value: 5432
    - description: PostgreSQL user
      name: user
    - description: PostgreSQL password
      kind: password
      name: password
    - description: PostgreSQL database name
      name: dbname
    - description: Using SSL via postgres `sslmode='require'` option. If the server
        does not accept SSL connections or the client certificate is not recognized
        the connection will fail
      kind: boolean
      name: ssl
      value: false
      value_post_processor: stringify
    - description: Scan only the specified comma-separated schemas to improve the
        performance of data extraction
      name: filter_schemas
    - kind: options
      name: default_replication_method
      options:
      - label: Log-based Incremental Replication
        value: LOG_BASED
      - label: Key-based Incremental Replication
        value: INCREMENTAL
      - label: Full Table Replication
        value: FULL_TABLE
    - description: Stop running the tap after certain number of seconds
      kind: integer
      name: max_run_seconds
      value: 43200
    - description: Stop running the tap when no data received from wal after certain
        number of seconds
      kind: integer
      name: logical_poll_total_seconds
      value: 10800
    - description: Stop running the tap if the newly received lsn is after the max
        lsn that was detected when the tap started
      kind: boolean
      name: break_at_end_lsn
      value: true
    settings_group_validation:
    - - host
      - port
      - user
      - password
      - dbname
- description: Single application for the entire DevOps lifecycle
  label: GitLab
  name: tap-gitlab
  namespace: tap_gitlab
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/gitlab.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-gitlab.git
    repo: https://gitlab.com/meltano/tap-gitlab
    settings:
    - description: GitLab API/instance URL. When an API path is omitted, `/api/v4/`
        is assumed.
      label: GitLab Instance
      name: api_url
      protected: true
      value: https://gitlab.com
    - description: GitLab personal access token or other API token.
      env_aliases:
      - GITLAB_API_TOKEN
      kind: password
      label: Access Token
      name: private_token
      placeholder: Ex. *****************
      value: ''
    - description: Space-separated names of groups to extract data from. Leave empty
        and provide a project name if you'd like to pull data from a project in a
        personal user namespace.
      env_aliases:
      - GITLAB_API_GROUPS
      label: Groups
      name: groups
      placeholder: Ex. my-organization
      value: ''
    - description: Space-separated `namespace/project` paths of projects to extract
        data from. Leave empty and provide a group name to extract data from all group
        projects.
      env_aliases:
      - GITLAB_API_PROJECTS
      label: Project
      name: projects
      placeholder: Ex. my-organization/project-1
      value: ''
    - description: Enable to pull in extra data (like Epics, Epic Issues and other
        entities) only available to GitLab Ultimate and GitLab.com Gold accounts.
      env_aliases:
      - GITLAB_API_ULTIMATE_LICENSE
      kind: boolean
      name: ultimate_license
      value: false
    - description: For each Merge Request, also fetch the MR's commits and create
        the join table `merge_request_commits` with the Merge Request and related
        Commit IDs. This can slow down extraction considerably because of the many
        API calls required.
      kind: boolean
      name: fetch_merge_request_commits
      value: false
    - description: For every Pipeline, also fetch extended details of each of these
        pipelines. This can slow down extraction considerably because of the many
        API calls required.
      kind: boolean
      name: fetch_pipelines_extended
      value: false
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      env_aliases:
      - GITLAB_API_START_DATE
      kind: date_iso8601
      name: start_date
    settings_group_validation:
    - - api_url
      - groups
      - start_date
    - - api_url
      - projects
      - start_date
- description: National Grid ESO's Carbon Emissions Intensity API
  label: Carbon Emissions Intensity
  name: tap-carbon-intensity
  namespace: tap_carbon
  variants:
  - capabilities:
    - discover
    hidden: true
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-carbon-intensity.git
    repo: https://gitlab.com/meltano/tap-carbon-intensity
- description: Accounting management platform
  label: Quickbooks
  name: tap-quickbooks
  namespace: tap_quickbooks
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/quickbooks.html
    name: hotgluexyz
    pip_url: git+https://github.com/hotgluexyz/tap-quickbooks.git
    repo: https://github.com/hotgluexyz/tap-quickbooks
    settings:
    - label: Realm ID
      name: realmId
    - kind: password
      label: Client ID
      name: client_id
    - kind: password
      name: client_secret
    - kind: password
      name: refresh_token
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    - description: Use Quickbooks Sandbox
      kind: boolean
      name: is_sandbox
      value: false
    - description: Select by default any new fields discovered in Quickbooks objects
      kind: boolean
      name: select_fields_by_default
      value: true
    - description: Generate a STATE message every N records
      kind: integer
      name: state_message_threshold
      value: 1000
    - kind: integer
      label: Maximum number of threads to use
      name: max_workers
      value: 8
    settings_group_validation:
    - - client_id
      - client_secret
      - refresh_token
      - realmId
      - start_date
- description: Issue and Project Tracking Software
  label: Jira
  name: tap-jira
  namespace: tap_jira
  variants:
  - capabilities:
    - discover
    - properties
    - state
    docs: https://hub.meltano.com/extractors/jira
    name: singer-io
    pip_url: git+https://github.com/singer-io/tap-jira.git
    repo: https://github.com/singer-io/tap-jira
    settings:
    - description: Your Jira username.
      label: Username
      name: username
    - description: Your Jira password.
      kind: password
      label: Password
      name: password
    - description: The base URL for your Jira instance.
      label: Base URL
      name: base_url
      placeholder: Ex. "https://mycompany.atlassian.net"
    - description: The client secret value used for OAuth authentication.
      kind: password
      label: OAuth Client Secret
      name: oauth_client_secret
    - description: The client ID used for OAuth authentication.
      label: OAuth Client ID
      name: oauth_client_id
    - description: The access token generated for your account.
      kind: password
      label: Access Token
      name: access_token
    - description: The cloud ID of your JIRA instance.
      label: Cloud ID
      name: cloud_id
    - description: The refresh token generated for your account.
      kind: password
      label: Refresh Token
      name: refresh_token
    - description: Specifies the date at which the tap will begin pulling data. This
        works only for the streams taht suppport it.
      kind: date_iso8601
      label: Start Date
      name: start_date
    - label: User Agent
      name: user_agent
      value: tap-jira via Meltano
    settings_group_validation:
    - - username
      - password
      - base_url
      - start_date
      - user_agent
    - - oauth_client_secret
      - oauth_client_id
      - access_token
      - cloud_id
      - refresh_token
      - start_date
      - user_agent
- description: Advertising Platform
  label: Bing Ads
  name: tap-bing-ads
  namespace: tap_bing_ads
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/bing-ads.html
    metadata:
      ad_group_performance_report:
        AbsoluteTopImpressionRatePercent:
          inclusion: available
          selected: false
        AbsoluteTopImpressionShareLostToBudgetPercent:
          inclusion: available
          selected: false
        AbsoluteTopImpressionShareLostToRankPercent:
          inclusion: available
          selected: false
        AbsoluteTopImpressionSharePercent:
          inclusion: available
          selected: false
        AudienceImpressionLostToBudgetPercent:
          inclusion: available
          selected: false
        AudienceImpressionLostToRankPercent:
          inclusion: available
          selected: false
        AudienceImpressionSharePercent:
          inclusion: available
          selected: false
        ClickSharePercent:
          inclusion: available
          selected: false
        ExactMatchImpressionSharePercent:
          inclusion: available
          selected: false
        ImpressionLostToAdRelevancePercent:
          inclusion: available
          selected: false
        ImpressionLostToBidPercent:
          inclusion: available
          selected: false
        ImpressionLostToBudgetPercent:
          inclusion: available
          selected: false
        ImpressionLostToExpectedCtrPercent:
          inclusion: available
          selected: false
        ImpressionLostToRankAggPercent:
          inclusion: available
          selected: false
        ImpressionLostToRankPercent:
          inclusion: available
          selected: false
        ImpressionSharePercent:
          inclusion: available
          selected: false
        TopImpressionRatePercent:
          inclusion: available
          selected: false
        TopImpressionShareLostToBudgetPercent:
          inclusion: available
          selected: false
        TopImpressionShareLostToRankPercent:
          inclusion: available
          selected: false
        TopImpressionSharePercent:
          inclusion: available
          selected: false
      campaign_performance_report:
        AbsoluteTopImpressionRatePercent:
          inclusion: available
          selected: false
        AbsoluteTopImpressionShareLostToBudgetPercent:
          inclusion: available
          selected: false
        AbsoluteTopImpressionShareLostToRankPercent:
          inclusion: available
          selected: false
        AbsoluteTopImpressionSharePercent:
          inclusion: available
          selected: false
        AudienceImpressionLostToBudgetPercent:
          inclusion: available
          selected: false
        AudienceImpressionLostToRankPercent:
          inclusion: available
          selected: false
        AudienceImpressionSharePercent:
          inclusion: available
          selected: false
        ClickSharePercent:
          inclusion: available
          selected: false
        ExactMatchImpressionSharePercent:
          inclusion: available
          selected: false
        ImpressionLostToAdRelevancePercent:
          inclusion: available
          selected: false
        ImpressionLostToBidPercent:
          inclusion: available
          selected: false
        ImpressionLostToBudgetPercent:
          inclusion: available
          selected: false
        ImpressionLostToExpectedCtrPercent:
          inclusion: available
          selected: false
        ImpressionLostToRankAggPercent:
          inclusion: available
          selected: false
        ImpressionLostToRankPercent:
          inclusion: available
          selected: false
        ImpressionSharePercent:
          inclusion: available
          selected: false
        TopImpressionRatePercent:
          inclusion: available
          selected: false
        TopImpressionShareLostToBudgetPercent:
          inclusion: available
          selected: false
        TopImpressionShareLostToRankPercent:
          inclusion: available
          selected: false
        TopImpressionSharePercent:
          inclusion: available
          selected: false
    name: singer-io
    pip_url: tap-bing-ads
    repo: https://github.com/singer-io/tap-bing-ads
    settings:
    - env: OAUTH_BING_ADS_DEVELOPER_TOKEN
      kind: password
      name: developer_token
    - env: OAUTH_BING_ADS_CLIENT_ID
      kind: password
      label: OAuth Client ID
      name: oauth_client_id
    - env: OAUTH_BING_ADS_CLIENT_SECRET
      kind: password
      label: OAuth Client Secret
      name: oauth_client_secret
    - kind: password
      name: refresh_token
    - label: Customer ID
      name: customer_id
    - label: Account ID(s)
      name: account_ids
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    settings_group_validation:
    - - customer_id
      - account_ids
      - oauth_client_id
      - oauth_client_secret
      - refresh_token
      - developer_token
      - start_date
- description: Support ticketing system & customer service platform
  label: Zendesk
  name: tap-zendesk
  namespace: tap_zendesk
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/zendesk.html
    name: twilio-labs
    pip_url: twilio-tap-zendesk
    repo: https://github.com/twilio-labs/twilio-tap-zendesk
    settings:
    - description: This is the email you use to login to your Zendesk dashboard. For
        API Authentication, `/token` is automatically appended to the email address
        and is not required in the configuration.
      kind: email
      label: Email
      name: email
      placeholder: Ex. me@my-organization.com
    - description: You can use the API Token authentication which can be generated
        from the Zendesk Admin page.
      documentation: https://support.zendesk.com/hc/en-us/articles/226022787-Generating-a-new-API-token-
      kind: password
      label: API Token
      name: api_token
      placeholder: Ex. *****************
    - description: To use OAuth, you will need to fetch an `access_token` from a configured
        Zendesk integration.
      documentation: https://support.zendesk.com/hc/en-us/articles/203663836
      kind: password
      label: Access Token
      name: access_token
    - description: 'When visiting your Zendesk instance, the URL is structured as
        follows: `SUBDOMAIN.zendesk.com`. For example, if the URL is `meltano.zendesk.com`,
        then the subdomain is `meltano`.

        '
      documentation: https://support.zendesk.com/hc/en-us/articles/221682747-Where-can-I-find-my-Zendesk-subdomain-
      label: Zendesk Subdomain
      name: subdomain
      placeholder: Ex. my-subdomain.zendesk.com
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      label: Start Date
      name: start_date
    settings_group_validation:
    - - email
      - api_token
      - subdomain
      - start_date
    - - access_token
      - subdomain
      - start_date
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/zendesk.html
    name: singer-io
    pip_url: tap-zendesk
    repo: https://github.com/singer-io/tap-zendesk
    settings:
    - kind: email
      name: email
      placeholder: Ex. me@my-organization.com
    - documentation: https://support.zendesk.com/hc/en-us/articles/226022787-Generating-a-new-API-token-
      kind: password
      label: API Token
      name: api_token
      placeholder: Ex. *****************
    - description: OAuth Access Token
      documentation: https://support.zendesk.com/hc/en-us/articles/203663836
      kind: password
      name: access_token
    - documentation: https://support.zendesk.com/hc/en-us/articles/221682747-Where-can-I-find-my-Zendesk-subdomain-
      label: Zendesk Subdomain
      name: subdomain
      placeholder: Ex. my-subdomain.zendesk.com
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    settings_group_validation:
    - - email
      - api_token
      - subdomain
      - start_date
    - - access_token
      - subdomain
      - start_date
- description: Customer-relationship management & customer success platform
  label: Salesforce
  name: tap-salesforce
  namespace: tap_salesforce
  variants:
  - capabilities:
    - properties
    - discover
    - state
    docs: https://hub.meltano.com/extractors/salesforce.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-salesforce.git
    repo: https://gitlab.com/meltano/tap-salesforce
    select:
    - Lead.*
    - Contact.*
    - User.*
    - OpportunityHistory.*
    - Account.*
    - Opportunity.*
    settings:
    - name: username
      placeholder: Ex. me@my-organization.com
    - kind: password
      label: Password
      name: password
      placeholder: Ex. *****************
    - description: Your Salesforce Account access token
      documentation: https://hub.meltano.com/extractors/salesforce.html#salesforce-setup
      kind: password
      label: Security Token
      name: security_token
      placeholder: Ex. *****************
    - label: Client ID
      name: client_id
    - kind: password
      name: client_secret
    - kind: password
      name: refresh_token
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    - description: Use Salesforce Sandbox
      kind: boolean
      name: is_sandbox
      value: false
    - kind: options
      label: API Type
      name: api_type
      options:
      - label: REST
        value: REST
      - label: BULK
        value: BULK
      value: REST
    - description: Select by default any new fields discovered in Salesforce objects
      kind: boolean
      name: select_fields_by_default
      value: true
    - description: Generate a STATE message every N records
      kind: integer
      name: state_message_threshold
      value: 1000
    - kind: integer
      label: Maximum number of threads to use
      name: max_workers
      value: 8
    settings_group_validation:
    - - username
      - password
      - security_token
      - start_date
    - - client_id
      - client_secret
      - refresh_token
      - start_date
- description: Subscription payments platform
  label: ReCharge
  name: tap-recharge
  namespace: tap_recharge
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/recharge.html
    name: singer-io
    pip_url: tap-recharge==1.0.3
    repo: https://github.com/singer-io/tap-recharge
    settings:
    - description: Private API Token
      kind: password
      name: access_token
      placeholder: Ex. 1a2b3c4d5e6f
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    - description: User agent to send to ReCharge along with API requests. Typically
        includes name of integration and an email address you can be reached at
      name: user_agent
      placeholder: Ex. tap-recharge via Meltano <user@example.com>
      value: tap-recharge via Meltano
- description: Customer Experience Platform
  label: AskNicely
  name: tap-ask-nicely
  namespace: tap_ask_nicely
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/ask-nicely
    name: mashey
    pip_url: git+https://github.com/Mashey/tap-ask-nicely.git
    repo: https://github.com/Mashey/tap-ask-nicely
    settings:
    - description: The subdomain of your Ask Nicely account.
      label: Subdomain
      name: subdomain
    - description: The API Key generated via your Ask Nicely account.
      documentation: https://asknicely.asknice.ly/help/apidocs/auth
      kind: password
      label: API Key
      name: api_key
    settings_group_validation:
    - - subdomain
      - api_key
- description: Financial management software
  label: Sage Intacct
  name: tap-intacct
  namespace: tap_intacct
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/intacct.html
    name: hotgluexyz
    pip_url: git+https://github.com/hotgluexyz/tap-intacct.git
    repo: https://github.com/hotgluexyz/tap-intacct
    settings:
    - label: Company Id
      name: company_id
    - label: Intacct Sender Id
      name: sender_id
    - kind: password
      label: Intacct Sender Password
      name: sender_password
    - label: Intacct User Id
      name: user_id
    - kind: password
      label: Intacct User Password
      name: user_password
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    - description: Select by default any new fields discovered in Quickbooks objects
      kind: boolean
      name: select_fields_by_default
      value: true
    - description: Generate a STATE message every N records
      kind: integer
      name: state_message_threshold
      value: 1000
    - kind: integer
      label: Maximum number of threads to use
      name: max_workers
      value: 8
    settings_group_validation:
    - - company_id
      - sender_id
      - sender_password
      - user_id
      - user_password
      - start_date
- description: Edge cloud computing services provider
  label: Fastly
  name: tap-fastly
  namespace: tap_fastly
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/fastly.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-fastly.git
    repo: https://gitlab.com/meltano/tap-fastly
    settings:
    - kind: password
      label: API Token
      name: api_token
      placeholder: Ex. *****************
    - kind: date_iso8601
      label: Start Date
      name: start_date
- description: Advertising Platform
  label: Google Ads
  name: tap-adwords
  namespace: tap_adwords
  variants:
  - capabilities:
    - properties
    - discover
    - state
    docs: https://hub.meltano.com/extractors/adwords.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/tap-adwords.git
    repo: https://gitlab.com/meltano/tap-adwords
    select:
    - campaigns.*
    - ad_groups.*
    - ads.*
    - accounts.*
    - KEYWORDS_PERFORMANCE_REPORT.customerID
    - KEYWORDS_PERFORMANCE_REPORT.account
    - KEYWORDS_PERFORMANCE_REPORT.currency
    - KEYWORDS_PERFORMANCE_REPORT.timeZone
    - KEYWORDS_PERFORMANCE_REPORT.clientName
    - KEYWORDS_PERFORMANCE_REPORT.campaign
    - KEYWORDS_PERFORMANCE_REPORT.campaignID
    - KEYWORDS_PERFORMANCE_REPORT.campaignState
    - KEYWORDS_PERFORMANCE_REPORT.adGroup
    - KEYWORDS_PERFORMANCE_REPORT.adGroupID
    - KEYWORDS_PERFORMANCE_REPORT.adGroupState
    - KEYWORDS_PERFORMANCE_REPORT.day
    - KEYWORDS_PERFORMANCE_REPORT.network
    - KEYWORDS_PERFORMANCE_REPORT.device
    - KEYWORDS_PERFORMANCE_REPORT.clicks
    - KEYWORDS_PERFORMANCE_REPORT.cost
    - KEYWORDS_PERFORMANCE_REPORT.impressions
    - KEYWORDS_PERFORMANCE_REPORT.interactions
    - KEYWORDS_PERFORMANCE_REPORT.engagements
    - KEYWORDS_PERFORMANCE_REPORT.conversions
    - KEYWORDS_PERFORMANCE_REPORT.allConv
    - KEYWORDS_PERFORMANCE_REPORT.views
    - KEYWORDS_PERFORMANCE_REPORT.activeViewViewableImpressions
    - KEYWORDS_PERFORMANCE_REPORT.activeViewMeasurableImpr
    - KEYWORDS_PERFORMANCE_REPORT.activeViewMeasurableCost
    - KEYWORDS_PERFORMANCE_REPORT.gmailClicksToWebsite
    - KEYWORDS_PERFORMANCE_REPORT.gmailSaves
    - KEYWORDS_PERFORMANCE_REPORT.gmailForwards
    - KEYWORDS_PERFORMANCE_REPORT.keywordID
    - KEYWORDS_PERFORMANCE_REPORT.keyword
    - KEYWORDS_PERFORMANCE_REPORT.keywordState
    - KEYWORDS_PERFORMANCE_REPORT.criterionServingStatus
    - KEYWORDS_PERFORMANCE_REPORT.destinationURL
    - KEYWORDS_PERFORMANCE_REPORT.matchType
    - KEYWORDS_PERFORMANCE_REPORT.topOfPageCPC
    - KEYWORDS_PERFORMANCE_REPORT.firstPageCPC
    - KEYWORDS_PERFORMANCE_REPORT.imprAbsTop
    - KEYWORDS_PERFORMANCE_REPORT.activeViewAvgCPM
    - KEYWORDS_PERFORMANCE_REPORT.activeViewViewableCTR
    - KEYWORDS_PERFORMANCE_REPORT.activeViewMeasurableImprImpr
    - KEYWORDS_PERFORMANCE_REPORT.activeViewViewableImprMeasurableImpr
    - KEYWORDS_PERFORMANCE_REPORT.allConvRate
    - KEYWORDS_PERFORMANCE_REPORT.allConvValue
    - KEYWORDS_PERFORMANCE_REPORT.avgCost
    - KEYWORDS_PERFORMANCE_REPORT.avgCPC
    - KEYWORDS_PERFORMANCE_REPORT.avgCPE
    - KEYWORDS_PERFORMANCE_REPORT.avgCPM
    - KEYWORDS_PERFORMANCE_REPORT.avgCPV
    - KEYWORDS_PERFORMANCE_REPORT.avgPosition
    - KEYWORDS_PERFORMANCE_REPORT.convRate
    - KEYWORDS_PERFORMANCE_REPORT.totalConvValue
    - KEYWORDS_PERFORMANCE_REPORT.costAllConv
    - KEYWORDS_PERFORMANCE_REPORT.costConv
    - KEYWORDS_PERFORMANCE_REPORT.costConvCurrentModel
    - KEYWORDS_PERFORMANCE_REPORT.crossDeviceConv
    - KEYWORDS_PERFORMANCE_REPORT.ctr
    - KEYWORDS_PERFORMANCE_REPORT.conversionsCurrentModel
    - KEYWORDS_PERFORMANCE_REPORT.convValueCurrentModel
    - KEYWORDS_PERFORMANCE_REPORT.engagementRate
    - KEYWORDS_PERFORMANCE_REPORT.interactionRate
    - KEYWORDS_PERFORMANCE_REPORT.interactionTypes
    - KEYWORDS_PERFORMANCE_REPORT.imprTop
    - KEYWORDS_PERFORMANCE_REPORT.valueAllConv
    - KEYWORDS_PERFORMANCE_REPORT.valueConv
    - KEYWORDS_PERFORMANCE_REPORT.valueConvCurrentModel
    - KEYWORDS_PERFORMANCE_REPORT.videoPlayedTo100
    - KEYWORDS_PERFORMANCE_REPORT.videoPlayedTo25
    - KEYWORDS_PERFORMANCE_REPORT.videoPlayedTo50
    - KEYWORDS_PERFORMANCE_REPORT.videoPlayedTo75
    - KEYWORDS_PERFORMANCE_REPORT.viewRate
    - KEYWORDS_PERFORMANCE_REPORT.viewThroughConv
    - KEYWORDS_PERFORMANCE_REPORT.searchAbsTopIS
    - KEYWORDS_PERFORMANCE_REPORT.searchLostAbsTopISBudget
    - KEYWORDS_PERFORMANCE_REPORT.searchLostTopISBudget
    - KEYWORDS_PERFORMANCE_REPORT.searchExactMatchIS
    - KEYWORDS_PERFORMANCE_REPORT.searchImprShare
    - KEYWORDS_PERFORMANCE_REPORT.searchLostAbsTopISRank
    - KEYWORDS_PERFORMANCE_REPORT.searchLostISRank
    - KEYWORDS_PERFORMANCE_REPORT.searchLostTopISRank
    - KEYWORDS_PERFORMANCE_REPORT.searchTopIS
    - AD_PERFORMANCE_REPORT.customerID
    - AD_PERFORMANCE_REPORT.account
    - AD_PERFORMANCE_REPORT.currency
    - AD_PERFORMANCE_REPORT.timeZone
    - AD_PERFORMANCE_REPORT.clientName
    - AD_PERFORMANCE_REPORT.campaign
    - AD_PERFORMANCE_REPORT.campaignID
    - AD_PERFORMANCE_REPORT.campaignState
    - AD_PERFORMANCE_REPORT.adGroup
    - AD_PERFORMANCE_REPORT.adGroupID
    - AD_PERFORMANCE_REPORT.adGroupState
    - AD_PERFORMANCE_REPORT.day
    - AD_PERFORMANCE_REPORT.network
    - AD_PERFORMANCE_REPORT.device
    - AD_PERFORMANCE_REPORT.clicks
    - AD_PERFORMANCE_REPORT.cost
    - AD_PERFORMANCE_REPORT.impressions
    - AD_PERFORMANCE_REPORT.interactions
    - AD_PERFORMANCE_REPORT.engagements
    - AD_PERFORMANCE_REPORT.conversions
    - AD_PERFORMANCE_REPORT.allConv
    - AD_PERFORMANCE_REPORT.views
    - AD_PERFORMANCE_REPORT.activeViewViewableImpressions
    - AD_PERFORMANCE_REPORT.activeViewMeasurableImpr
    - AD_PERFORMANCE_REPORT.activeViewMeasurableCost
    - AD_PERFORMANCE_REPORT.gmailClicksToWebsite
    - AD_PERFORMANCE_REPORT.gmailSaves
    - AD_PERFORMANCE_REPORT.gmailForwards
    - AD_PERFORMANCE_REPORT.adID
    - AD_PERFORMANCE_REPORT.adState
    - AD_PERFORMANCE_REPORT.approvalStatus
    - AD_PERFORMANCE_REPORT.adType
    - AD_PERFORMANCE_REPORT.adStrength
    - AD_PERFORMANCE_REPORT.autoAppliedAdSuggestion
    - AD_PERFORMANCE_REPORT.ad
    - AD_PERFORMANCE_REPORT.descriptionLine1
    - AD_PERFORMANCE_REPORT.descriptionLine2
    - AD_PERFORMANCE_REPORT.finalURL
    - AD_PERFORMANCE_REPORT.displayURL
    - AD_PERFORMANCE_REPORT.description
    - AD_PERFORMANCE_REPORT.headline1
    - AD_PERFORMANCE_REPORT.headline2
    - AD_PERFORMANCE_REPORT.path1
    - AD_PERFORMANCE_REPORT.businessName
    - AD_PERFORMANCE_REPORT.callToActionTextResponsive
    - AD_PERFORMANCE_REPORT.shortHeadline
    - AD_PERFORMANCE_REPORT.longHeadline
    - AD_PERFORMANCE_REPORT.promotionTextResponsive
    - AD_PERFORMANCE_REPORT.responsiveSearchAdPath1
    - AD_PERFORMANCE_REPORT.responsiveSearchAdHeadlines
    - AD_PERFORMANCE_REPORT.responsiveSearchAdDescriptions
    - AD_PERFORMANCE_REPORT.gmailAdBusinessName
    - AD_PERFORMANCE_REPORT.gmailAdHeadline
    - AD_PERFORMANCE_REPORT.gmailAdDescription
    - AD_PERFORMANCE_REPORT.imageAdName
    - AD_PERFORMANCE_REPORT.businessNameMultiAssetResponsiveDisplay
    - AD_PERFORMANCE_REPORT.longHeadlineMultiAssetResponsiveDisplay
    - AD_PERFORMANCE_REPORT.headlinesMultiAssetResponsiveDisplay
    - AD_PERFORMANCE_REPORT.callToActionTextMultiAssetResponsiveDisplay
    - AD_PERFORMANCE_REPORT.promotionTextMultiAssetResponsiveDisplay
    - AD_PERFORMANCE_REPORT.imprAbsTop
    - AD_PERFORMANCE_REPORT.activeViewAvgCPM
    - AD_PERFORMANCE_REPORT.activeViewViewableCTR
    - AD_PERFORMANCE_REPORT.activeViewMeasurableImprImpr
    - AD_PERFORMANCE_REPORT.activeViewViewableImprMeasurableImpr
    - AD_PERFORMANCE_REPORT.allConvRate
    - AD_PERFORMANCE_REPORT.allConvValue
    - AD_PERFORMANCE_REPORT.avgCost
    - AD_PERFORMANCE_REPORT.avgCPC
    - AD_PERFORMANCE_REPORT.avgCPE
    - AD_PERFORMANCE_REPORT.avgCPM
    - AD_PERFORMANCE_REPORT.avgCPV
    - AD_PERFORMANCE_REPORT.avgPosition
    - AD_PERFORMANCE_REPORT.convRate
    - AD_PERFORMANCE_REPORT.totalConvValue
    - AD_PERFORMANCE_REPORT.costAllConv
    - AD_PERFORMANCE_REPORT.costConv
    - AD_PERFORMANCE_REPORT.costConvCurrentModel
    - AD_PERFORMANCE_REPORT.crossDeviceConv
    - AD_PERFORMANCE_REPORT.ctr
    - AD_PERFORMANCE_REPORT.conversionsCurrentModel
    - AD_PERFORMANCE_REPORT.convValueCurrentModel
    - AD_PERFORMANCE_REPORT.engagementRate
    - AD_PERFORMANCE_REPORT.interactionRate
    - AD_PERFORMANCE_REPORT.interactionTypes
    - AD_PERFORMANCE_REPORT.imprTop
    - AD_PERFORMANCE_REPORT.valueAllConv
    - AD_PERFORMANCE_REPORT.valueConv
    - AD_PERFORMANCE_REPORT.valueConvCurrentModel
    - AD_PERFORMANCE_REPORT.videoPlayedTo100
    - AD_PERFORMANCE_REPORT.videoPlayedTo25
    - AD_PERFORMANCE_REPORT.videoPlayedTo50
    - AD_PERFORMANCE_REPORT.videoPlayedTo75
    - AD_PERFORMANCE_REPORT.viewRate
    - AD_PERFORMANCE_REPORT.viewThroughConv
    settings:
    - description: Your Developer Token for Google AdWord Application
      env: OAUTH_GOOGLE_ADWORDS_DEVELOPER_TOKEN
      kind: password
      label: Developer Token
      name: developer_token
      placeholder: Ex. *****************
    - description: Your Google OAuth Client ID
      env: OAUTH_GOOGLE_ADWORDS_CLIENT_ID
      kind: password
      label: OAuth Client ID
      name: oauth_client_id
      placeholder: Ex. 123456789012345.apps.googleusercontent.com
    - description: Your Google OAuth Client Secret
      env: OAUTH_GOOGLE_ADWORDS_CLIENT_SECRET
      kind: password
      label: OAuth Client Secret
      name: oauth_client_secret
      placeholder: Ex. *****************
    - description: The Refresh Token generated through the OAuth flow run using your
        OAuth Client and your Developer Token
      kind: oauth
      label: Access Token
      name: refresh_token
      oauth:
        provider: google-adwords
      placeholder: Ex. *****************
    - description: A comma-separated list of Ad Account IDs to replicate data from
      label: Account ID(s)
      name: customer_ids
      placeholder: Ex. 1234567890,1234567891,1234567892
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
    - description: Date up to when historical data will be extracted.
      kind: date_iso8601
      name: end_date
    - description: The User Agent for your OAuth Client (used in requests made to
        the AdWords API)
      label: User Agent for your OAuth Client
      name: user_agent
      placeholder: Ex. tap-adwords via Meltano <user@example.com>
      value: tap-adwords via Meltano
    - description: How many Days before the Start Date to fetch data for Performance
        Reports
      kind: integer
      label: Conversion Window Days
      name: conversion_window_days
      value: 0
    - description: Primary Keys for the selected Entities (Streams)
      kind: object
      label: Primary Keys
      name: primary_keys
      value:
        AD_PERFORMANCE_REPORT:
        - customerID
        - campaignID
        - adGroupID
        - adID
        - day
        - network
        - device
        KEYWORDS_PERFORMANCE_REPORT:
        - customerID
        - campaignID
        - adGroupID
        - keywordID
        - day
        - network
        - device
    settings_group_validation:
    - - developer_token
      - oauth_client_id
      - oauth_client_secret
      - refresh_token
      - user_agent
      - customer_ids
      - start_date
- description: Ecommerce platform
  label: Shopify
  name: tap-shopify
  namespace: tap_shopify
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/shopify.html
    name: singer-io
    pip_url: tap-shopify
    repo: https://github.com/singer-io/tap-shopify
    select:
    - abandoned_checkouts.*
    - collects.*
    - custom_collections.*
    - customers.*
    - order_refunds.*
    - orders.*
    - products.*
    - transactions.*
    settings:
    - label: Store Subdomain
      name: shop
      placeholder: Ex. my-first-store
    - kind: password
      label: Private App API Password
      name: api_key
      placeholder: Ex. shppa_1a2b3c4d5e6f
    - description: Determines how much historical data will be extracted. Please be
        aware that the larger the time period and amount of data, the longer the initial
        extraction can be expected to take.
      kind: date_iso8601
      name: start_date
- description: Video conferencing software
  label: Zoom
  name: tap-zoom
  namespace: tap_zoom
  variants:
  - capabilities:
    - catalog
    - discover
    docs: https://hub.meltano.com/extractors/zoom.html
    name: mashey
    pip_url: git+https://github.com/mashey/tap-zoom.git
    repo: https://github.com/mashey/tap-zoom
    settings:
    - documentation: https://marketplace.zoom.us/docs/guides/auth/jwt
      kind: password
      label: JSON Web Token
      name: jwt
    - documentation: https://marketplace.zoom.us/docs/guides/auth/oauth
      name: client_id
    - documentation: https://marketplace.zoom.us/docs/guides/auth/oauth
      kind: password
      name: client_secret
    - documentation: https://marketplace.zoom.us/docs/guides/auth/oauth
      kind: password
      name: refresh_token
    settings_group_validation:
    - - jwt
    - - client_id
      - client_secret
      - refresh_token
- description: Data extractor for CSV and Excel files from any smart_open supported
    transport (S3, SFTP, localhost, etc...)
  label: Spreadsheets Anywhere
  name: tap-spreadsheets-anywhere
  namespace: tap_spreadsheets_anywhere
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    docs: https://hub.meltano.com/extractors/spreadsheets-anywhere.html
    name: ets
    pip_url: git+https://github.com/ets/tap-spreadsheets-anywhere.git
    repo: https://github.com/ets/tap-spreadsheets-anywhere
    settings:
    - description: An array holding json objects that each describe a set of targeted
        source files. See docs for details.
      kind: array
      name: tables
files:
- name: gitlab-ci
  namespace: gitlab_ci
  pip_url: git+https://gitlab.com/meltano/files-gitlab-ci.git
  repo: https://gitlab.com/meltano/files-gitlab-ci
- name: airflow
  namespace: airflow
  pip_url: git+https://gitlab.com/meltano/files-airflow.git
  repo: https://gitlab.com/meltano/files-airflow
  update:
    orchestrate/dags/meltano.py: true
- name: docker-compose
  namespace: docker_compose
  pip_url: git+https://gitlab.com/meltano/files-docker-compose.git
  repo: https://gitlab.com/meltano/files-docker-compose
- name: dbt
  namespace: dbt
  pip_url: git+https://gitlab.com/meltano/files-dbt.git@config-version-2
  repo: https://gitlab.com/meltano/files-dbt
  update:
    transform/profile/profiles.yml: true
- name: docker
  namespace: docker
  pip_url: git+https://gitlab.com/meltano/files-docker.git
  repo: https://gitlab.com/meltano/files-docker
loaders:
- description: CSV loader
  label: Comma Separated Values (CSV)
  name: target-csv
  namespace: target_csv
  variants:
  - docs: https://hub.meltano.com/loaders/csv.html
    name: hotgluexyz
    pip_url: git+https://github.com/hotgluexyz/target-csv.git@0.3.3
    repo: https://github.com/hotgluexyz/target-csv
    settings:
    - description: Sets the destination path the CSV files are written to, relative
        to the project root. The directory needs to exist already, it will not be
        created automatically. To write CSV files to the project root, set an empty
        string (`""`).
      name: destination_path
      value: output
    - description: A one-character string used to separate fields. It defaults to
        a comma (,).
      kind: options
      name: delimiter
      options:
      - label: Comma (,)
        value: ','
      - label: Tab (  )
        value: \t
      - label: Semi-colon (;)
        value: ;
      - label: Pipe (|)
        value: '|'
      value: ','
    - description: A one-character string used to quote fields containing special
        characters, such as the delimiter or quotechar, or which contain new-line
        characters. It defaults to single quote (').
      kind: options
      name: quotechar
      options:
      - label: Single Quote (')
        value: ''''
      - label: Double Quote (")
        value: '"'
      value: ''''
  - docs: https://hub.meltano.com/loaders/csv.html
    name: singer-io
    pip_url: target-csv
    repo: https://github.com/singer-io/target-csv
    settings:
    - description: Sets the destination path the CSV files are written to, relative
        to the project root. The directory needs to exist already, it will not be
        created automatically. To write CSV files to the project root, set an empty
        string (`""`).
      name: destination_path
      value: output
    - description: A one-character string used to separate fields. It defaults to
        a comma (,).
      kind: options
      name: delimiter
      options:
      - label: Comma (,)
        value: ','
      - label: Tab (  )
        value: \t
      - label: Semi-colon (;)
        value: ;
      - label: Pipe (|)
        value: '|'
      value: ','
    - description: A one-character string used to quote fields containing special
        characters, such as the delimiter or quotechar, or which contain new-line
        characters. It defaults to single quote (').
      kind: options
      name: quotechar
      options:
      - label: Single Quote (')
        value: ''''
      - label: Double Quote (")
        value: '"'
      value: ''''
- description: SQLite database loader
  label: SQLite
  name: target-sqlite
  namespace: target_sqlite
  variants:
  - dialect: sqlite
    docs: https://hub.meltano.com/loaders/sqlite.html
    name: meltano
    pip_url: git+https://gitlab.com/meltano/target-sqlite.git
    repo: https://gitlab.com/meltano/target-sqlite
    settings:
    - description: Name of the SQLite database file to be used or created, relative
        to the project root. The `.db` extension is optional and will be added automatically
        when omitted.
      env_aliases:
      - SQLITE_DATABASE
      label: Database Name
      name: database
      value: warehouse
    - description: How many records are sent to SQLite at a time?
      kind: integer
      name: batch_size
      value: 50
    - description: Name of the column used for recording the timestamp when Data are
        loaded to SQLite.
      name: timestamp_column
      value: __loaded_at
    settings_group_validation:
    - - batch_size
- description: BigQuery loader
  label: BigQuery
  name: target-bigquery
  namespace: target_bigquery
  variants:
  - dialect: bigquery
    docs: https://hub.meltano.com/loaders/bigquery.html
    name: adswerve
    pip_url: git+https://github.com/adswerve/target-bigquery.git@v0.10.2
    repo: https://github.com/adswerve/target-bigquery
    settings:
    - description: BigQuery project
      name: project_id
    - description: BigQuery dataset
      name: dataset_id
      value: $MELTANO_EXTRACT__LOAD_SCHEMA
    - description: Dataset location
      name: location
      value: US
    - description: Fully qualified path to `client_secrets.json` for your service
        account.
      env_aliases:
      - GOOGLE_APPLICATION_CREDENTIALS
      name: credentials_path
      value: $MELTANO_PROJECT_ROOT/client_secrets.json
    - description: Validate records
      kind: boolean
      name: validate_records
      value: false
    - description: Add `_time_extracted` and `_time_loaded` metadata columns
      kind: boolean
      name: add_metadata_columns
      value: false
    - description: Replication method, `append` or `truncate`
      kind: options
      name: replication_method
      options:
      - label: Append
        value: append
      - label: Truncate
        value: truncate
      value: append
    - description: Add prefix to table name
      name: table_prefix
    - description: Add suffix to table name
      name: table_suffix
    - description: Maximum cache size in MB
      name: max_cache
      value: 50
    settings_group_validation:
    - - project_id
      - dataset_id
      - location
      - credentials_path
    target_schema: $TARGET_BIGQUERY_DATASET_ID
- description: PostgreSQL database loader
  dialect: postgres
  label: PostgreSQL
  name: target-postgres
  namespace: target_postgres
  target_schema: $TARGET_POSTGRES_SCHEMA
  variants:
  - docs: https://hub.meltano.com/loaders/postgres.html
    name: datamill-co
    pip_url: singer-target-postgres
    repo: https://github.com/datamill-co/target-postgres
    settings:
    - env: TARGET_POSTGRES_HOST
      env_aliases:
      - PG_ADDRESS
      name: postgres_host
      value: localhost
    - env: TARGET_POSTGRES_PORT
      env_aliases:
      - PG_PORT
      kind: integer
      name: postgres_port
      value: 5432
    - env: TARGET_POSTGRES_DATABASE
      env_aliases:
      - PG_DATABASE
      name: postgres_database
    - env: TARGET_POSTGRES_USERNAME
      env_aliases:
      - PG_USERNAME
      name: postgres_username
    - env: TARGET_POSTGRES_PASSWORD
      env_aliases:
      - PG_PASSWORD
      kind: password
      name: postgres_password
    - env: TARGET_POSTGRES_SCHEMA
      env_aliases:
      - PG_SCHEMA
      name: postgres_schema
      value: $MELTANO_EXTRACT__LOAD_SCHEMA
    - description: 'Refer to the libpq docs for more information about SSL: https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-PARAMKEYWORDS'
      env: TARGET_POSTGRES_SSLMODE
      name: postgres_sslmode
      value: prefer
    - description: Only used if a SSL request w/ a client certificate is being made
      env: TARGET_POSTGRES_SSLCERT
      name: postgres_sslcert
      value: ~/.postgresql/postgresql.crt
    - description: Only used if a SSL request w/ a client certificate is being made
      env: TARGET_POSTGRES_SSLKEY
      name: postgres_sslkey
      value: ~/.postgresql/postgresql.key
    - description: Used for authentication of a server SSL certificate
      env: TARGET_POSTGRES_SSLROOTCERT
      name: postgres_sslrootcert
      value: ~/.postgresql/root.crt
    - description: Used for authentication of a server SSL certificate
      env: TARGET_POSTGRES_SSLCRL
      name: postgres_sslcrl
      value: ~/.postgresql/root.crl
    - description: Include `false` in your config to disable `target-postgres` from
        crashing on invalid records
      kind: boolean
      name: invalid_records_detect
      value: true
    - description: Include a positive value `n` in your config to allow for `target-postgres`
        to encounter at most `n` invalid records per stream before giving up.
      kind: integer
      name: invalid_records_threshold
      value: 0
    - description: 'Include `true` in your config to disable Singer Usage Logging:
        https://github.com/datamill-co/target-postgres#usage-logging'
      kind: boolean
      name: disable_collection
      value: false
    - description: The level for logging. Set to `DEBUG` to get things like queries
        executed, timing of those queries, etc.
      kind: options
      name: logging_level
      options:
      - label: Debug
        value: DEBUG
      - label: Info
        value: INFO
      - label: Warning
        value: WARNING
      - label: Error
        value: ERROR
      - label: Critical
        value: CRITICAL
      value: INFO
    - description: Whether the Target should create tables which have no records present
        in Remote.
      kind: boolean
      name: persist_empty_tables
      value: false
    - description: The maximum number of rows to buffer in memory before writing to
        the destination table in Postgres
      kind: integer
      name: max_batch_rows
      value: 200000
    - description: 'The maximum number of bytes to buffer in memory before writing
        to the destination table in Postgres. Default: 100MB in bytes'
      kind: integer
      name: max_buffer_size
      value: 104857600
    - description: How often, in rows received, to count the buffered rows and bytes
        to check if a flush is necessary. There's a slight performance penalty to
        checking the buffered records count or bytesize, so this controls how often
        this is polled in order to mitigate the penalty. This value is usually not
        necessary to set as the default is dynamically adjusted to check reasonably
        often.
      kind: integer
      name: batch_detection_threshold
    - description: Whether the Target should emit `STATE` messages to stdout for further
        consumption. In this mode, which is on by default, STATE messages are buffered
        in memory until all the records that occurred before them are flushed according
        to the batch flushing schedule the target is configured with.
      kind: boolean
      name: state_support
      value: true
    - description: Whether the Target should create column indexes on the important
        columns used during data loading. These indexes will make data loading slightly
        slower but the deduplication phase much faster. Defaults to on for better
        baseline performance.
      kind: boolean
      name: add_upsert_indexes
      value: true
    - description: Raw SQL statement(s) to execute as soon as the connection to Postgres
        is opened by the target. Useful for setup like `SET ROLE` or other connection
        state that is important.
      name: before_run_sql
    - description: Raw SQL statement(s) to execute as soon as the connection to Postgres
        is opened by the target. Useful for setup like `SET ROLE` or other connection
        state that is important.
      name: after_run_sql
    settings_group_validation:
    - - postgres_host
      - postgres_port
      - postgres_database
      - postgres_username
      - postgres_password
      - postgres_schema
  - docs: https://hub.meltano.com/loaders/postgres--transferwise.html
    name: transferwise
    pip_url: pipelinewise-target-postgres
    repo: https://github.com/transferwise/pipelinewise-target-postgres
    settings:
    - description: PostgreSQL host
      env_aliases:
      - PG_ADDRESS
      name: host
      value: localhost
    - description: PostgreSQL port
      env_aliases:
      - PG_PORT
      kind: integer
      name: port
      value: 5432
    - description: PostgreSQL user
      env_aliases:
      - PG_USERNAME
      name: user
    - description: PostgreSQL password
      env_aliases:
      - PG_PASSWORD
      kind: password
      name: password
    - description: PostgreSQL database name
      env_aliases:
      - PG_DATABASE
      name: dbname
    - kind: boolean
      name: ssl
      value: false
      value_post_processor: stringify
    - description: Name of the schema where the tables will be created. If `schema_mapping`
        is not defined then every stream sent by the tap is loaded into this schema.
      env_aliases:
      - TARGET_POSTGRES_SCHEMA
      - PG_SCHEMA
      name: default_target_schema
      value: $MELTANO_EXTRACT__LOAD_SCHEMA
    - description: Maximum number of rows in each batch. At the end of each batch,
        the rows in the batch are loaded into Postgres.
      kind: integer
      name: batch_size_rows
      value: 100000
    - description: 'Flush and load every stream into Postgres when one batch is full.
        Warning: This may trigger the COPY command to use files with low number of
        records.'
      kind: boolean
      name: flush_all_streams
      value: false
    - description: The number of threads used to flush tables. 0 will create a thread
        for each stream, up to parallelism_max. -1 will create a thread for each CPU
        core. Any other positive number will create that number of threads, up to
        parallelism_max.
      kind: integer
      name: parallelism
      value: 0
    - description: Max number of parallel threads to use when flushing tables.
      kind: integer
      name: parallelism_max
      value: 16
    - description: Grant USAGE privilege on newly created schemas and grant SELECT
        privilege on newly created tables to a specific role or a list of roles. If
        `schema_mapping` is not defined then every stream sent by the tap is granted
        accordingly.
      name: default_target_schema_select_permission
    - description: 'Useful if you want to load multiple streams from one tap to multiple
        Postgres schemas.

        If the tap sends the `stream_id` in `<schema_name>-<table_name>` format then
        this option overwrites the `default_target_schema` value. Note, that using
        `schema_mapping` you can overwrite the `default_target_schema_select_permission`
        value to grant SELECT permissions to different groups per schemas or optionally
        you can create indices automatically for the replicated tables.

        '
      kind: object
      name: schema_mapping
    - description: Metadata columns add extra row level information about data ingestions,
        (i.e. when was the row read in source, when was inserted or deleted in postgres
        etc.) Metadata columns are creating automatically by adding extra columns
        to the tables with a column prefix `_SDC_`. The column names are following
        the stitch naming conventions documented at https://www.stitchdata.com/docs/data-structure/integration-schemas#sdc-columns.
        Enabling metadata columns will flag the deleted rows by setting the `_SDC_DELETED_AT`
        metadata column. Without the `add_metadata_columns` option the deleted rows
        from singer taps will not be recongisable in Postgres.
      kind: boolean
      name: add_metadata_columns
      value: false
    - description: When `hard_delete` option is true then DELETE SQL commands will
        be performed in Postgres to delete rows in tables. It's achieved by continuously
        checking the `_SDC_DELETED_AT` metadata column sent by the singer tap. Due
        to deleting rows requires metadata columns, `hard_delete` option automatically
        enables the `add_metadata_columns` option as well.
      kind: boolean
      name: hard_delete
      value: false
    - description: Object type RECORD items from taps can be transformed to flattened
        columns by creating columns automatically. When value is 0 (default) then
        flattening functionality is turned off.
      kind: integer
      name: data_flattening_max_level
      value: 0
    - description: Log based and Incremental replications on tables with no Primary
        Key cause duplicates when merging UPDATE events. When set to true, stop loading
        data if no Primary Key is defined.
      kind: boolean
      name: primary_key_required
      value: true
    - description: Validate every single record message to the corresponding JSON
        schema. This option is disabled by default and invalid RECORD messages will
        fail only at load time by Postgres. Enabling this option will detect invalid
        records earlier but could cause performance degradation.
      kind: boolean
      name: validate_records
      value: false
    - description: '(Default: platform-dependent) Directory of temporary CSV files
        with RECORD messages.'
      name: temp_dir
    settings_group_validation:
    - - host
      - port
      - user
      - password
      - dbname
      - default_target_schema
  - docs: https://hub.meltano.com/loaders/postgres--meltano.html
    name: meltano
    original: true
    pip_url: git+https://github.com/meltano/target-postgres.git
    repo: https://github.com/meltano/target-postgres
    settings:
    - aliases:
      - username
      env_aliases:
      - PG_USERNAME
      - POSTGRES_USER
      name: user
      value: warehouse
    - env_aliases:
      - PG_PASSWORD
      - POSTGRES_PASSWORD
      kind: password
      name: password
      value: warehouse
    - aliases:
      - address
      env_aliases:
      - PG_ADDRESS
      - POSTGRES_HOST
      name: host
      value: localhost
    - env_aliases:
      - PG_PORT
      - POSTGRES_PORT
      kind: integer
      name: port
      value: 5502
    - aliases:
      - database
      env_aliases:
      - PG_DATABASE
      - POSTGRES_DBNAME
      label: Database Name
      name: dbname
      value: warehouse
    - description: Lets you set `user`, `password`, `host`, `port`, and `dbname` in
        one go using a `postgresql://` URI. Takes precedence over the other settings
        when set.
      env_aliases:
      - PG_URL
      - POSTGRES_URL
      label: URL
      name: url
    - env_aliases:
      - PG_SCHEMA
      - POSTGRES_SCHEMA
      name: schema
      value: $MELTANO_EXTRACT__LOAD_SCHEMA
    settings_group_validation:
    - - url
      - schema
    - - user
      - password
      - host
      - port
      - dbname
      - schema
- description: JSONL loader
  label: JSON Lines (JSONL)
  name: target-jsonl
  namespace: target_jsonl
  variants:
  - docs: https://hub.meltano.com/loaders/jsonl.html
    name: andyh1203
    pip_url: target-jsonl
    repo: https://github.com/andyh1203/target-jsonl
    settings:
    - description: Sets the destination path the JSONL files are written to, relative
        to the project root. The directory needs to exist already, it will not be
        created automatically. To write JSONL files to the project root, set an empty
        string (`""`).
      name: destination_path
      value: output
    - description: Specifies if the files should get timestamped
      kind: boolean
      label: Include timestamp in file names
      name: do_timestamp_file
      value: false
- description: Amazon Redshift loader
  label: Amazon Redshift
  name: target-redshift
  namespace: target_redshift
  variants:
  - capabilities:
    - catalog
    - discover
    - state
    dialect: redshift
    docs: https://hub.meltano.com/loaders/redshift.html
    executable: target-redshift
    name: transferwise
    pip_url: pipelinewise-target-redshift
    repo: https://github.com/transferwise/pipelinewise-target-redshift
    settings:
    - description: Redshift host
      name: host
    - description: Redshift port
      kind: integer
      name: port
      value: 5439
    - description: Redshift database name
      label: Database Name
      name: dbname
    - description: Redshift user name
      label: User name
      name: user
    - description: Redshift password
      kind: password
      name: password
    - description: AWS S3 bucket name
      label: S3 Bucket name
      name: s3_bucket
    - description: Name of the schema where the tables will be created. If schema_mapping
        is not defined then every stream sent by the tap is loaded into this schema.
      env_aliases:
      - TARGET_REDSHIFT_SCHEMA
      name: default_target_schema
      value: $MELTANO_EXTRACT__LOAD_SCHEMA
    - description: AWS profile name for profile based authentication. If not provided,
        AWS_PROFILE environment variable will be used.
      env_aliases:
      - AWS_PROFILE
      label: AWS profile name
      name: aws_profile
    - description: S3 Access Key Id. Used for S3 and Redshift copy operations. If
        not provided, AWS_ACCESS_KEY_ID environment variable will be used.
      env_aliases:
      - AWS_ACCESS_KEY_ID
      kind: password
      label: AWS S3 Access Key ID
      name: aws_access_key_id
    - description: S3 Secret Access Key. Used for S3 and Redshift copy operations.
        If not provided, AWS_SECRET_ACCESS_KEY environment variable will be used.
      env_aliases:
      - AWS_SECRET_ACCESS_KEY
      kind: password
      label: AWS S3 Secret Access Key
      name: aws_secret_access_key
    - description: S3 AWS STS token for temporary credentials. If not provided, AWS_SESSION_TOKEN
        environment variable will be used.
      env_aliases:
      - AWS_SESSION_TOKEN
      kind: password
      label: AWS S3 Session Token
      name: aws_session_token
    - description: AWS Role ARN to be used for the Redshift COPY operation. Used instead
        of the given AWS keys for the COPY operation if provided - the keys are still
        used for other S3 operations
      label: AWS Redshift COPY role ARN
      name: aws_redshift_copy_role_arn
    - description: S3 Object ACL
      label: AWS S3 ACL
      name: s3_acl
    - description: A static prefix before the generated S3 key names. Using prefixes
        you can upload files into specific directories in the S3 bucket. Default(None)
      label: S3 Key Prefix
      name: s3_key_prefix
    - description: 'Parameters to use in the COPY command when loading data to Redshift.
        Some basic file formatting parameters are fixed values and not recommended
        overriding them by custom values. They are like: `CSV GZIP DELIMITER '',''
        REMOVEQUOTES ESCAPE`.

        '
      label: COPY options
      name: copy_options
      value: EMPTYASNULL BLANKSASNULL TRIMBLANKS TRUNCATECOLUMNS TIMEFORMAT 'auto'
        COMPUPDATE OFF STATUPDATE OFF
    - description: Maximum number of rows in each batch. At the end of each batch,
        the rows in the batch are loaded into Redshift.
      kind: integer
      name: batch_size_rows
      value: 100000
    - description: Flush and load every stream into Redshift when one batch is full.
        Warning - This may trigger the COPY command to use files with low number of
        records, and may cause performance problems.
      kind: boolean
      name: flush_all_streams
      value: false
    - description: The number of threads used to flush tables. 0 will create a thread
        for each stream, up to parallelism_max. -1 will create a thread for each CPU
        core. Any other positive number will create that number of threads, up to
        parallelism_max.
      kind: integer
      name: parallelism
      value: 0
    - description: Max number of parallel threads to use when flushing tables.
      kind: integer
      name: max_parallelism
      value: 16
    - description: Grant USAGE privilege on newly created schemas and grant SELECT
        privilege on newly created tables to a specific list of users or groups. If
        schema_mapping is not defined then every stream sent by the tap is granted
        accordingly.
      name: default_target_schema_select_permissions
    - description: Useful if you want to load multiple streams from one tap to multiple
        Redshift schemas. If the tap sends the stream_id in <schema_name>-<table_name>
        format then this option overwrites the default_target_schema value. Note,
        that using schema_mapping you can overwrite the default_target_schema_select_permissions
        value to grant SELECT permissions to different groups per schemas or optionally
        you can create indices automatically for the replicated tables.
      kind: object
      name: schema_mapping
    - description: By default the connector caches the available table structures
        in Redshift at startup. In this way it doesn't need to run additional queries
        when ingesting data to check if altering the target tables is required. With
        disable_table_cache option you can turn off this caching. You will always
        see the most recent table structures but will cause an extra query runtime.
      kind: boolean
      name: disable_table_cache
      value: false
    - description: Metadata columns add extra row level information about data ingestions,
        (i.e. when was the row read in source, when was inserted or deleted in redshift
        etc.) Metadata columns are creating automatically by adding extra columns
        to the tables with a column prefix _SDC_. The metadata columns are documented
        at https://transferwise.github.io/pipelinewise/data_structure/sdc-columns.html.
        Enabling metadata columns will flag the deleted rows by setting the _SDC_DELETED_AT
        metadata column. Without the add_metadata_columns option the deleted rows
        from singer taps will not be recongisable in Redshift.
      kind: boolean
      name: add_metadata_columns
      value: false
    - description: When hard_delete option is true then DELETE SQL commands will be
        performed in Redshift to delete rows in tables. It's achieved by continuously
        checking the _SDC_DELETED_AT metadata column sent by the singer tap. Due to
        deleting rows requires metadata columns, hard_delete option automatically
        enables the add_metadata_columns option as well.
      kind: boolean
      name: hard_delete
      value: false
    - description: Object type RECORD items from taps can be loaded into VARIANT columns
        as JSON (default) or we can flatten the schema by creating columns automatically.
        When value is 0 (default) then flattening functionality is turned off.
      kind: integer
      name: data_flattening_max_level
      value: 0
    - description: Log based and Incremental replications on tables with no Primary
        Key cause duplicates when merging UPDATE events. When set to true, stop loading
        data if no Primary Key is defined.
      kind: boolean
      name: primary_key_required
      value: true
    - description: Validate every single record message to the corresponding JSON
        schema. This option is disabled by default and invalid RECORD messages will
        fail only at load time by Redshift. Enabling this option will detect invalid
        records earlier but could cause performance degradation.
      kind: boolean
      name: validate_records
      value: false
    - description: Do not update existing records when Primary Key is defined. Useful
        to improve performance when records are immutable, e.g. events
      kind: boolean
      name: skip_updates
      value: false
    - description: The compression method to use when writing files to S3 and running
        Redshift COPY.
      kind: options
      name: compression
      options:
      - label: None
        value: ''
      - label: gzip
        value: gzip
      - label: bzip2
        value: bzip2
    - description: The number of slices to split files into prior to running COPY
        on Redshift. This should be set to the number of Redshift slices. The number
        of slices per node depends on the node size of the cluster - run SELECT COUNT(DISTINCT
        slice) slices FROM stv_slices to calculate this. Defaults to 1.
      kind: integer
      name: slices
      value: 1
    - description: '(Default: platform-dependent) Directory of temporary CSV files
        with RECORD messages.'
      label: Temp directory
      name: temp_dir
    settings_group_validation:
    - - host
      - port
      - user
      - password
      - dbname
      - s3_bucket
      - default_target_schema
      - aws_profile
    - - host
      - port
      - user
      - password
      - dbname
      - s3_bucket
      - default_target_schema
      - aws_access_key_id
      - aws_secret_access_key
    - - host
      - port
      - user
      - password
      - dbname
      - s3_bucket
      - default_target_schema
      - aws_session_token
    target_schema: $TARGET_REDSHIFT_SCHEMA
- description: Snowflake database loader
  dialect: snowflake
  label: Snowflake
  name: target-snowflake
  namespace: target_snowflake
  target_schema: $TARGET_SNOWFLAKE_SCHEMA
  variants:
  - docs: https://hub.meltano.com/loaders/snowflake.html
    name: datamill-co
    pip_url: target-snowflake
    repo: https://github.com/datamill-co/target-snowflake
    settings:
    - description: '`ACCOUNT` might require the `region` and `cloud` platform where
        your account is located, in the form of: `<your_account_name>.<region_id>.<cloud>`
        (e.g. `xy12345.east-us-2.azure`)

        Refer to Snowflake''s documentation about Account: https://docs.snowflake.net/manuals/user-guide/connecting.html#your-snowflake-account-name-and-url

        '
      env: TARGET_SNOWFLAKE_ACCOUNT
      env_aliases:
      - SF_ACCOUNT
      name: snowflake_account
    - env: TARGET_SNOWFLAKE_USERNAME
      env_aliases:
      - SF_USER
      name: snowflake_username
    - env: TARGET_SNOWFLAKE_PASSWORD
      env_aliases:
      - SF_PASSWORD
      kind: password
      name: snowflake_password
    - description: If not specified, Snowflake will use the user's default role.
      env: TARGET_SNOWFLAKE_ROLE
      env_aliases:
      - SF_ROLE
      name: snowflake_role
    - env: TARGET_SNOWFLAKE_DATABASE
      env_aliases:
      - SF_DATABASE
      name: snowflake_database
    - description: Specifies the authentication provider for snowflake to use. Valud
        options are the internal one ("snowflake"), a browser session ("externalbrowser"),
        or Okta ("https://<your_okta_account_name>.okta.com"). See the snowflake docs
        for more details.
      name: snowflake_authenticator
      value: snowflake
    - env: TARGET_SNOWFLAKE_WAREHOUSE
      env_aliases:
      - SF_WAREHOUSE
      name: snowflake_warehouse
    - env: TARGET_SNOWFLAKE_SCHEMA
      env_aliases:
      - SF_SCHEMA
      name: snowflake_schema
      value: $MELTANO_EXTRACT__LOAD_SCHEMA
      value_processor: upcase_string
    - description: Include `false` in your config to disable crashing on invalid records
      kind: boolean
      name: invalid_records_detect
      value: true
    - description: Include a positive value `n` in your config to allow at most `n`
        invalid records per stream before giving up.
      kind: integer
      name: invalid_records_threshold
      value: 0
    - description: 'Include `true` in your config to disable Singer Usage Logging:
        https://github.com/datamill-co/target-snowflake#usage-logging'
      kind: boolean
      name: disable_collection
      value: false
    - description: The level for logging. Set to `DEBUG` to get things like queries
        executed, timing of those queries, etc.
      kind: options
      name: logging_level
      options:
      - label: Debug
        value: DEBUG
      - label: Info
        value: INFO
      - label: Warning
        value: WARNING
      - label: Error
        value: ERROR
      - label: Critical
        value: CRITICAL
      value: INFO
    - description: Whether the Target should create tables which have no records present
        in Remote.
      kind: boolean
      name: persist_empty_tables
      value: false
    - description: Whether the Target should emit `STATE` messages to stdout for further
        consumption. In this mode, which is on by default, STATE messages are buffered
        in memory until all the records that occurred before them are flushed according
        to the batch flushing schedule the target is configured with.
      kind: boolean
      name: state_support
      value: true
    - description: When included, use S3 to stage files. Bucket where staging files
        should be uploaded to.
      name: target_s3.bucket
    - description: Prefix for staging file uploads to allow for better delineation
        of tmp files
      name: target_s3.key_prefix
    - kind: password
      name: target_s3.aws_access_key_id
    - kind: password
      name: target_s3.aws_secret_access_key
    settings_group_validation:
    - - snowflake_account
      - snowflake_username
      - snowflake_password
      - snowflake_database
      - snowflake_warehouse
      - snowflake_schema
  - docs: https://hub.meltano.com/loaders/snowflake--transferwise.html
    name: transferwise
    pip_url: pipelinewise-target-snowflake
    repo: https://github.com/transferwise/pipelinewise-target-snowflake
    settings:
    - description: Snowflake account name (i.e. rtXXXXX.eu-central-1)
      env_aliases:
      - SF_ACCOUNT
      name: account
      placeholder: E.g. rtXXXXX.eu-central-1
    - aliases:
      - database
      description: Snowflake Database name
      env_aliases:
      - TARGET_SNOWFLAKE_DATABASE
      - SF_DATABASE
      name: dbname
    - aliases:
      - username
      description: Snowflake User
      env_aliases:
      - TARGET_SNOWFLAKE_USERNAME
      - SF_USER
      name: user
    - description: Snowflake Password
      env_aliases:
      - SF_PASSWORD
      kind: password
      name: password
    - description: Snowflake virtual warehouse name
      env_aliases:
      - SF_WAREHOUSE
      name: warehouse
    - description: S3 Bucket name
      name: s3_bucket
    - description: Named external stage name created at pre-requirements section.
        Has to be a fully qualified name including the schema name
      name: stage
    - description: Named file format name created at pre-requirements section. Has
        to be a fully qualified name including the schema name.
      name: file_format
    - aliases:
      - schema
      description: Name of the schema where the tables will be created, without database
        prefix. If `schema_mapping` is not defined then every stream sent by the tap
        is loaded into this schema.
      env_aliases:
      - TARGET_SNOWFLAKE_SCHEMA
      - SF_SCHEMA
      name: default_target_schema
      value: $MELTANO_EXTRACT__LOAD_SCHEMA
      value_processor: upcase_string
    - description: S3 Access Key Id. If not provided, `AWS_ACCESS_KEY_ID` environment
        variable or IAM role will be used
      kind: password
      name: aws_access_key_id
    - description: S3 Secret Access Key. If not provided, `AWS_SECRET_ACCESS_KEY`
        environment variable or IAM role will be used
      kind: password
      name: aws_secret_access_key
    - description: AWS Session token. If not provided, `AWS_SESSION_TOKEN` environment
        variable will be used
      kind: password
      name: aws_session_token
    - description: AWS profile name for profile based authentication. If not provided,
        `AWS_PROFILE` environment variable will be used.
      name: aws_profile
    - description: A static prefix before the generated S3 key names. Using prefixes
        you can upload files into specific directories in the S3 bucket.
      name: s3_key_prefix
    - description: The complete URL to use for the constructed client. This is allowing
        to use non-native s3 account.
      name: s3_endpoint_url
    - description: Default region when creating new connections
      name: s3_region_name
    - description: S3 ACL name to set on the uploaded files
      name: s3_acl
    - description: Maximum number of rows in each batch. At the end of each batch,
        the rows in the batch are loaded into Snowflake.
      kind: integer
      name: batch_size_rows
      value: 100000
    - description: 'Flush and load every stream into Snowflake when one batch is full.
        Warning: This may trigger the COPY command to use files with low number of
        records, and may cause performance problems.'
      kind: boolean
      name: flush_all_streams
      value: false
    - description: The number of threads used to flush tables. 0 will create a thread
        for each stream, up to parallelism_max. -1 will create a thread for each CPU
        core. Any other positive number will create that number of threads, up to
        parallelism_max.
      kind: integer
      name: parallelism
      value: 0
    - description: Max number of parallel threads to use when flushing tables.
      kind: integer
      name: parallelism_max
      value: 16
    - description: Grant USAGE privilege on newly created schemas and grant SELECT
        privilege on newly created tables to a specific role or a list of roles. If
        `schema_mapping` is not defined then every stream sent by the tap is granted
        accordingly.
      name: default_target_schema_select_permission
    - description: 'Useful if you want to load multiple streams from one tap to multiple
        Snowflake schemas.

        If the tap sends the `stream_id` in `<schema_name>-<table_name>` format then
        this option overwrites the `default_target_schema` value. Note, that using
        `schema_mapping` you can overwrite the `default_target_schema_select_permission`
        value to grant SELECT permissions to different groups per schemas or optionally
        you can create indices automatically for the replicated tables.

        '
      kind: object
      name: schema_mapping
    - description: By default the connector caches the available table structures
        in Snowflake at startup. In this way it doesn't need to run additional queries
        when ingesting data to check if altering the target tables is required. With
        `disable_table_cache` option you can turn off this caching. You will always
        see the most recent table structures but will cause an extra query runtime.
      kind: boolean
      name: disable_table_cache
      value: false
    - description: When this is defined, Client-Side Encryption is enabled. The data
        in S3 will be encrypted, No third parties, including Amazon AWS and any ISPs,
        can see data in the clear. Snowflake COPY command will decrypt the data once
        it's in Snowflake. The master key must be 256-bit length and must be encoded
        as base64 string.
      kind: password
      name: client_side_encryption_master_key
    - description: Required when `client_side_encryption_master_key` is defined. The
        name of the encrypted stage object in Snowflake that created separately and
        using the same encryption master key.
      name: client_side_encryption_stage_object
    - description: Metadata columns add extra row level information about data ingestions,
        (i.e. when was the row read in source, when was inserted or deleted in snowflake
        etc.) Metadata columns are creating automatically by adding extra columns
        to the tables with a column prefix `_SDC_`. The column names are following
        the stitch naming conventions documented at https://www.stitchdata.com/docs/data-structure/integration-schemas#sdc-columns.
        Enabling metadata columns will flag the deleted rows by setting the `_SDC_DELETED_AT`
        metadata column. Without the `add_metadata_columns` option the deleted rows
        from singer taps will not be recongisable in Snowflake.
      kind: boolean
      name: add_metadata_columns
      value: false
    - description: When `hard_delete` option is true then DELETE SQL commands will
        be performed in Snowflake to delete rows in tables. It's achieved by continuously
        checking the `_SDC_DELETED_AT` metadata column sent by the singer tap. Due
        to deleting rows requires metadata columns, `hard_delete` option automatically
        enables the `add_metadata_columns` option as well.
      kind: boolean
      name: hard_delete
      value: false
    - description: Object type RECORD items from taps can be loaded into VARIANT columns
        as JSON (default) or we can flatten the schema by creating columns automatically.
        When value is 0 (default) then flattening functionality is turned off.
      kind: integer
      name: data_flattening_max_level
      value: 0
    - description: Log based and Incremental replications on tables with no Primary
        Key cause duplicates when merging UPDATE events. When set to true, stop loading
        data if no Primary Key is defined.
      kind: boolean
      name: primary_key_required
      value: true
    - description: Validate every single record message to the corresponding JSON
        schema. This option is disabled by default and invalid RECORD messages will
        fail only at load time by Snowflake. Enabling this option will detect invalid
        records earlier but could cause performance degradation.
      kind: boolean
      name: validate_records
      value: false
    - description: '(Default: platform-dependent) Directory of temporary CSV files
        with RECORD messages.'
      name: temp_dir
    - description: Generate uncompressed CSV files when loading to Snowflake. Normally,
        by default GZIP compressed files are generated.
      kind: boolean
      name: no_compression
      value: false
    - description: Optional string to tag executed queries in Snowflake. Replaces
        tokens `schema` and `table` with the appropriate values. The tags are displayed
        in the output of the Snowflake `QUERY_HISTORY`, `QUERY_HISTORY_BY_*` functions.
      name: query_tag
    settings_group_validation:
    - - account
      - dbname
      - user
      - password
      - warehouse
      - s3_bucket
      - stage
      - file_format
      - default_target_schema
  - docs: https://hub.meltano.com/loaders/snowflake--meltano.html
    name: meltano
    original: true
    pip_url: git+https://gitlab.com/meltano/target-snowflake.git
    repo: https://gitlab.com/meltano/target-snowflake
    settings:
    - description: Account Name in Snowflake (https://XXXXX.snowflakecomputing.com)
      env_aliases:
      - SF_ACCOUNT
      - SNOWFLAKE_ACCOUNT
      name: account
    - description: The username you use for logging in
      env_aliases:
      - SF_USER
      - SNOWFLAKE_USERNAME
      name: username
    - description: The password you use for logging in
      env_aliases:
      - SF_PASSWORD
      - SNOWFLAKE_PASSWORD
      kind: password
      name: password
    - description: Role to be used for loading the data, e.g. `LOADER`. Also this
        role is GRANTed usage to all tables and schemas created
      env_aliases:
      - SF_ROLE
      - SNOWFLAKE_ROLE
      name: role
    - description: The name of the Snowflake database you want to use
      env_aliases:
      - SF_DATABASE
      - SNOWFLAKE_DATABASE
      name: database
    - description: The name of the Snowflake warehouse you want to use
      env_aliases:
      - SF_WAREHOUSE
      - SNOWFLAKE_WAREHOUSE
      name: warehouse
    - env_aliases:
      - SF_SCHEMA
      - SNOWFLAKE_SCHEMA
      name: schema
      value: $MELTANO_EXTRACT__LOAD_SCHEMA
      value_processor: upcase_string
    - description: How many records are sent to Snowflake at a time?
      kind: integer
      name: batch_size
      value: 5000
    - description: Name of the column used for recording the timestamp when Data are
        uploaded to Snowflake.
      name: timestamp_column
      value: __loaded_at
    settings_group_validation:
    - - account
      - username
      - password
      - role
      - database
      - warehouse
      - schema
models:
- name: model-gitlab
  namespace: tap_gitlab
  pip_url: git+https://gitlab.com/meltano/model-gitlab.git
  repo: https://gitlab.com/meltano/model-gitlab
  variant: meltano
- name: model-carbon-intensity
  namespace: tap_carbon
  pip_url: git+https://gitlab.com/meltano/model-carbon-intensity.git
  repo: https://gitlab.com/meltano/model-carbon-intensity
  variant: meltano
- name: model-google-analytics
  namespace: tap_google_analytics
  pip_url: git+https://gitlab.com/meltano/model-google-analytics.git
  repo: https://gitlab.com/meltano/model-google-analytics
  variant: meltano
- name: model-facebook
  namespace: tap_facebook
  pip_url: git+https://gitlab.com/meltano/model-facebook.git
  repo: https://gitlab.com/meltano/model-facebook
  variant: meltano
- name: model-zendesk
  namespace: tap_zendesk
  pip_url: git+https://gitlab.com/meltano/model-zendesk.git
  repo: https://gitlab.com/meltano/model-zendesk
  variant: meltano
- name: model-stripe
  namespace: tap_stripe
  pip_url: git+https://gitlab.com/meltano/model-stripe.git
  repo: https://gitlab.com/meltano/model-stripe
  variant: meltano
- name: model-gitlab-ultimate
  namespace: tap_gitlab_ultimate
  pip_url: git+https://gitlab.com/meltano/model-gitlab-ultimate.git
  repo: https://gitlab.com/meltano/model-gitlab-ultimate
  variant: meltano
- name: model-adwords
  namespace: tap_adwords
  pip_url: git+https://gitlab.com/meltano/model-adwords.git
  repo: https://gitlab.com/meltano/model-adwords
  variant: meltano
- name: model-shopify
  namespace: tap_shopify
  pip_url: git+https://gitlab.com/meltano/model-shopify.git
  repo: https://gitlab.com/meltano/model-shopify
  variant: meltano
- name: model-gitflix
  namespace: tap_gitflix
  pip_url: git+https://gitlab.com/jschatz1/model-gitflix.git
  repo: https://gitlab.com/jschatz1/model-gitflix
  variant: meltano
- name: model-salesforce
  namespace: tap_salesforce
  pip_url: git+https://gitlab.com/meltano/model-salesforce.git
  repo: https://gitlab.com/meltano/model-salesforce
  variant: meltano
orchestrators:
- docs: https://meltano.com/docs/orchestration.html
  name: airflow
  namespace: airflow
  pip_url: apache-airflow==2.1.2 --constraint https://raw.githubusercontent.com/apache/airflow/constraints-2.1.2/constraints-${MELTANO__PYTHON_VERSION}.txt
  repo: https://github.com/apache/airflow
  settings:
  - env: AIRFLOW__CORE__DAGS_FOLDER
    name: core.dags_folder
    value: $MELTANO_PROJECT_ROOT/orchestrate/dags
  - env: AIRFLOW__CORE__PLUGINS_FOLDER
    name: core.plugins_folder
    value: $MELTANO_PROJECT_ROOT/orchestrate/plugins
  - env: AIRFLOW__CORE__SQL_ALCHEMY_CONN
    name: core.sql_alchemy_conn
    value: sqlite:///$MELTANO_PROJECT_ROOT/.meltano/orchestrators/airflow/airflow.db
  - env: AIRFLOW__CORE__LOAD_EXAMPLES
    name: core.load_examples
    value: false
  - env: AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION
    name: core.dags_are_paused_at_creation
    value: false
transformers:
- commands:
    clean:
      args: clean
      description: Delete all folders in the clean-targets list (usually the dbt_modules
        and target directories.)
    compile:
      args: compile --models $DBT_MODELS
      description: Generates executable SQL from source model, test, and analysis
        files. Compiled SQL files are written to the target/ directory.
    deps:
      args: deps
      description: Pull the most recent version of the dependencies listed in packages.yml
    run:
      args: run --models $DBT_MODELS
      description: Compile SQL and execute against the current target database.
    seed:
      args: seed
      description: Load data from csv files into your data warehouse.
    snapshot:
      args: snapshot
      description: Execute snapshots defined in your project.
    test:
      args: test
      description: Runs tests on data in deployed models.
  docs: https://meltano.com/docs/transforms.html
  name: dbt
  namespace: dbt
  pip_url: dbt==0.21.0
  repo: https://github.com/fishtown-analytics/dbt
  settings:
  - name: project_dir
    value: $MELTANO_PROJECT_ROOT/transform
  - env: DBT_PROFILES_DIR
    name: profiles_dir
    value: $MELTANO_PROJECT_ROOT/transform/profile
  - name: target
    value: $MELTANO_LOAD__DIALECT
  - name: source_schema
    value: $MELTANO_LOAD__TARGET_SCHEMA
  - name: target_schema
    value: analytics
  - name: models
    value: $MELTANO_TRANSFORM__PACKAGE_NAME $MELTANO_EXTRACTOR_NAMESPACE my_meltano_project
transforms:
- name: tap-shopify
  namespace: tap_shopify
  pip_url: https://gitlab.com/meltano/dbt-tap-shopify.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-shopify
  variant: meltano
  vars:
    schema: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}'
- name: tap-adwords
  namespace: tap_adwords
  pip_url: https://gitlab.com/meltano/dbt-tap-adwords.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-adwords
  variant: meltano
  vars:
    schema: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}'
- name: tap-facebook
  namespace: tap_facebook
  pip_url: https://gitlab.com/meltano/dbt-tap-facebook.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-facebook
  variant: meltano
  vars:
    schema: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}'
- name: tap-carbon-intensity
  namespace: tap_carbon
  pip_url: https://gitlab.com/meltano/dbt-tap-carbon-intensity.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-carbon-intensity
  variant: meltano
  vars:
    entry_table: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}.entry'
    generationmix_table: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}.generationmix'
    region_table: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}.region'
- name: tap-zendesk
  namespace: tap_zendesk
  pip_url: https://gitlab.com/meltano/dbt-tap-zendesk.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-zendesk
  variant: meltano
  vars:
    schema: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}'
- name: tap-google-analytics
  namespace: tap_google_analytics
  pip_url: https://gitlab.com/meltano/dbt-tap-google-analytics.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-google-analytics
  variant: meltano
  vars:
    schema: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}'
- name: tap-salesforce
  namespace: tap_salesforce
  pip_url: https://gitlab.com/meltano/dbt-tap-salesforce.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-salesforce
  variant: meltano
  vars:
    schema: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}'
- name: tap-gitlab
  namespace: tap_gitlab
  pip_url: https://gitlab.com/meltano/dbt-tap-gitlab.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-gitlab
  variant: meltano
  vars:
    schema: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}'
    ultimate_license: '{{ env_var(''GITLAB_API_ULTIMATE_LICENSE'', False) }}'
- name: tap-stripe
  namespace: tap_stripe
  pip_url: https://gitlab.com/meltano/dbt-tap-stripe.git@config-version-2
  repo: https://gitlab.com/meltano/dbt-tap-stripe
  variant: meltano
  vars:
    livemode: false
    schema: '{{ env_var(''DBT_SOURCE_SCHEMA'') }}'
utilities:
- commands:
    lint:
      args: lint
      description: Lint SQL in transform models
  name: sqlfluff
  namespace: sqlfluff
  pip_url: sqlfluff[dbt]
version: 19
