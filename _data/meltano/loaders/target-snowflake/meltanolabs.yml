capabilities:
- about
- activate-version
- hard-delete
- schema-flattening
- stream-maps
description: Snowflake database loader
domain_url: https://www.snowflake.com/
executable: target-snowflake
keywords:
- meltano_sdk
- database
label: Snowflake
logo_url: /assets/logos/loaders/snowflake.png
maintenance_status: active
name: target-snowflake
namespace: target_snowflake
next_steps: ''
pip_url: meltanolabs-target-snowflake
quality: gold
repo: https://github.com/MeltanoLabs/target-snowflake
settings:
- description: Your account identifier. See [Account 
    Identifiers](https://docs.snowflake.com/en/user-guide/admin-account-identifier.html).
  kind: string
  label: Account
  name: account
- description: Whether to add metadata columns.
  kind: boolean
  label: Add Record Metadata
  name: add_record_metadata
  value: true
- description: Maximum number of rows in each batch.
  kind: integer
  label: Batch Size Rows
  name: batch_size_rows
- description: Whether to remove batch files after processing.
  kind: boolean
  label: Clean Up Batch Files
  name: clean_up_batch_files
  value: true
- description: The initial database for the Snowflake session.
  kind: string
  label: Database
  name: database
- description: The default target database schema name to use for all streams.
  kind: string
  label: Default Target Schema
  name: default_target_schema
- description: 'One or more LCID locale strings to produce localized output for: https://faker.readthedocs.io/en/master/#localization'
  kind: array
  label: Faker Locale
  name: faker_config.locale
- description: 'Value to seed the Faker generator for deterministic output: https://faker.readthedocs.io/en/master/#seeding-the-generator'
  kind: string
  label: Faker Seed
  name: faker_config.seed
- description: "'True' to enable schema flattening and automatically expand nested
    properties."
  kind: boolean
  label: Enable Schema Flattening
  name: flattening_enabled
- description: The max depth to flatten schemas.
  kind: integer
  label: Max Flattening Depth
  name: flattening_max_depth
- description: Hard delete records.
  kind: boolean
  label: Hard Delete
  name: hard_delete
  value: false
- description: The method to use when loading data into the destination. `append-only`
    will always write all input records whether that records already exists or not.
    `upsert` will update existing records and insert new records. `overwrite` will
    delete all existing records and insert all input records.
  kind: options
  label: Load Method
  name: load_method
  options:
  - label: Append Only
    value: append-only
  - label: Upsert
    value: upsert
  - label: Overwrite
    value: overwrite
  value: append-only
- description: The password for your Snowflake user.
  kind: password
  label: Password
  name: password
  sensitive: true
- description: The private key contents. For KeyPair authentication either private_key
    or private_key_path must be provided.
  kind: password
  label: Private Key
  name: private_key
  sensitive: true
- description: Passphrase to decrypt private key if encrypted.
  kind: password
  label: Private Key Passphrase
  name: private_key_passphrase
  sensitive: true
- description: Path to file containing private key. For KeyPair authentication either
    private_key or private_key_path must be provided.
  kind: password
  label: Private Key Path
  name: private_key_path
  sensitive: true
- description: Whether to process `ACTIVATE_VERSION` messages.
  kind: boolean
  label: Process `ACTIVATE_VERSION` messages
  name: process_activate_version_messages
  value: true
- description: The initial role for the session.
  kind: string
  label: Role
  name: role
- description: The initial schema for the Snowflake session.
  kind: string
  label: Schema
  name: schema
- description: User-defined config values to be used within map expressions.
  kind: object
  label: User Stream Map Configuration
  name: stream_map_config
- description: Config object for stream maps capability. For more information check
    out [Stream Maps](https://sdk.meltano.com/en/latest/stream_maps.html).
  kind: object
  label: Stream Maps
  name: stream_maps
- description: Whether to use SSO authentication using an external browser.
  kind: boolean
  label: Use Browser Authentication
  name: use_browser_authentication
  value: false
- description: The login name for your Snowflake user.
  kind: string
  label: User
  name: user
- description: Whether to validate the schema of the incoming streams.
  kind: boolean
  label: Validate Records
  name: validate_records
  value: true
- description: The initial warehouse for the session.
  kind: string
  label: Warehouse
  name: warehouse
settings_group_validation:
- - account
  - database
  - password
  - user
settings_preamble: |
  ### Snowflake Account Quickstart

  <iframe width="560" height="315" src="https://www.youtube.com/embed/9vEFxw-0nxI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

  This target has an interactive feature that will help you get a Snowflake account initialized with everything needed to get started loading data.

  - User
  - Role
  - Warehouse
  - Database
  - Proper grants

  If you don't have a Snowflake account yet you can sign up for a [free trial](https://trial.snowflake.com/).

  Run the following command to get started with the interactive CLI. The CLI will print the SQL queries it is planning to run and confirm with you before it makes any changes.

  ```bash
  meltano invoke target-snowflake --initialize
  ```

  The CLI will ask you to provide information about the new user/role/etc. you want to create but it will also need SYSADMIN credentials to execute the queries. You should prepare the following inputs:

  - Account (e.g. `lqnwlrc-onb17812`)
  - User that has SYSADMIN and SECURITYADMIN access. These comes default with the user that created the Snowflake account.
  - The password for your SYSADMIN user.

  After the CLI is done, you should have a new user/role/etc. created and ready to use. You can now use the CLI to load data into Snowflake.
usage: ''
variant: meltanolabs
