logo_url: /assets/logos/loaders/pipelinewise-s3-csv.png
variant: transferwise
description: AWS S3 - CSV File Format
usage: ''
settings_preamble: ''
repo: https://github.com/transferwise/pipelinewise-target-s3-csv
pip_url: git+https://github.com/transferwise/pipelinewise-target-s3-csv.git
next_steps: ''
namespace: pipelinewise_target_s3_csv
name: target-s3-csv
maintenance_status: active
label: S3 CSV
keywords: []
domain_url: https://aws.amazon.com/s3/
docs: https://transferwise.github.io/pipelinewise/
capabilities: []
settings_group_validation:
- - s3_bucket
settings:
- name: aws_access_key_id
  kind: password
  label: S3 Access Key Id
  description: If not provided, AWS_ACCESS_KEY_ID environment variable will be used.

- name: aws_secret_access_key
  kind: password
  label: S3 Secret Access Key
  description: If not provided, AWS_SECRET_ACCESS_KEY environment variable will be used.

- name: aws_session_token
  kind: password
  label: AWS Session token
  description: If not provided, AWS_SESSION_TOKEN environment variable will be used.

- name: aws_endpoint_url
  label: AWS endpoint URL
  description: AWS endpoint URL

- name: aws_profile
  label: AWS profile
  description: Name for profile based authentication. If not provided, AWS_PROFILE environment variable will be used.

- name: s3_bucket
  label: S3 Bucket name
  description: S3 Bucket name

- name: s3_key_prefix
  label: S3 Key Prefix
  description: (Default - None) A static prefix before the generated S3 key names. Using prefixes you can

- name: delimiter
  label: Delimiter
  description: (Default - ',') A one-character string used to separate fields.

- name: quotechar
  label: Quote Char
  description: (Default - '"') A one-character string used to quote fields containing special characters, such as the delimiter or quotechar, or which contain new-line characters.

- name: add_metadata_columns
  kind: boolean
  label: Add Metadata Columns
  description: (Default -  False) Metadata columns add extra row level information about data ingestions, (i.e. when was the row read in source, when was inserted or deleted in snowflake etc.) Metadata columns are creating automatically by adding extra columns to the tables with a column prefix _SDC_. The column names are following the stitch naming conventions documented at https://www.stitchdata.com/docs/data-structure/integration-schemas#sdc-columns. Enabling metadata columns will flag the deleted rows by setting the _SDC_DELETED_AT metadata column. Without the add_metadata_columns option the deleted rows from singer taps will not be recongisable in Snowflake.

- name: encryption_type
  label: S3 Access Key Id
  description: (Default - 'none') The type of encryption to use. Current supported options are - 'none' and 'KMS'.

- name: encryption_key
  label: Encryption Key
  description: A reference to the encryption key to use for data encryption. For KMS encryption, this should be the name of the KMS encryption key ID (e.g. '1234abcd-1234-1234-1234-1234abcd1234'). This field is ignored if 'encryption_type' is none or blank.

- name: compression
  label: Compression
  description: The type of compression to apply before uploading. Supported options are none (default) and gzip. For gzipped files, the file extension will automatically be changed to .csv.gz for all files.

- name: naming_convention
  label: Naming Convention
  description: (Default - None) Custom naming convention of the s3 key. Replaces tokens date, stream, and timestamp with the appropriate values.
    Supports "folders" in s3 keys e.g. folder/folder2/{stream}/export_date={date}/{timestamp}.csv.
    Honors the s3_key_prefix, if set, by prepending the "filename". E.g. naming_convention = folder1/my_file.csv and s3_key_prefix = prefix_ results in folder1/prefix_my_file.csv

- name: temp_dir
  label: S3 Access Key Id
  description: (Default - platform-dependent) Directory of temporary CSV files with RECORD messages.
