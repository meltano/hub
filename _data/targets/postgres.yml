name: PostgreSQL # TODO: Rename to label, so "postgres" can be "name"? Or use "identifier" for "postgres"?
type: target
target_type: database
description: For loading data into PostgreSQL
dialect: postgresql
singer_name: target-postgres
variants:
    - name: datamill-co
      maintainer:
        name: Data Mill # TODO: Move to separate data list of maintainers per variant ID
        url: https://datamill.co/
      maintenance_status: Active
      default: true
      repo: https://github.com/datamill-co/target-postgres
      pip_url: singer-target-postgres
      dependencies: > # TODO: Should this be a list? Relation to https://gitlab.com/meltano/singer-sdk/-/issues/117?
        `target-postgres` [requires](https://www.psycopg.org/docs/install.html#runtime-requirements) the
        [`libpq` library](https://www.postgresql.org/docs/current/libpq.html) to be available on your system.
        If you've installed PostgreSQL, you should already have it, but you can also install it by itself using the
        [`libpq-dev` package](https://pkgs.org/download/libpq-dev) on Ubuntu/Debian or the
        [`libpq` Homebrew formula](https://formulae.brew.sh/formula/libpq) on macOS.
      settings_group_validation: # TODO: There has to be a better way to express this
        - ['postgres_host', 'postgres_port', 'postgres_database', 'postgres_username', 'postgres_password', 'postgres_schema']
      settings: # TODO: Express using JSON schema, like SDK does. Meltano can map types to its own kinds
      - name: postgres_host
        value: localhost
      - name: postgres_port
        kind: integer
        value: 5432
      - name: postgres_database
      - name: postgres_username
      - name: postgres_password
        kind: password # TODO: Making `password` a separate kind comes from `input[type]` in HTML, but perhaps the type and the sensitive nature of this field are orthogonal properties
      - name: postgres_schema
        schema_id: true
      - name: postgres_sslmode
        value: prefer
        description: "Refer to the libpq docs for more information about SSL: https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-PARAMKEYWORDS"
      - name: postgres_sslcert
        value: "~/.postgresql/postgresql.crt"
        description: Only used if a SSL request w/ a client certificate is being made
      - name: postgres_sslkey
        value: "~/.postgresql/postgresql.key"
        description: Only used if a SSL request w/ a client certificate is being made
      - name: postgres_sslrootcert
        value: "~/.postgresql/root.crt"
        description: Used for authentication of a server SSL certificate
      - name: postgres_sslcrl
        value: "~/.postgresql/root.crl"
        description: Used for authentication of a server SSL certificate
      - name: invalid_records_detect
        kind: boolean
        value: true
        description: Include `false` in your config to disable `target-postgres` from crashing on invalid records
      - name: invalid_records_threshold
        kind: integer
        value: 0
        description: Include a positive value `n` in your config to allow for `target-postgres` to encounter at most `n` invalid records per stream before giving up.
      - name: disable_collection
        kind: boolean
        value: false
        description: "Include `true` in your config to disable Singer Usage Logging: https://github.com/datamill-co/target-postgres#usage-logging"
      - name: logging_level
        kind: options
        value: INFO
        options:
          - label: Debug
            value: DEBUG
          - label: Info
            value: INFO
          - label: Warning
            value: WARNING
          - label: Error
            value: ERROR
          - label: Critical
            value: CRITICAL
        description: The level for logging. Set to `DEBUG` to get things like queries executed, timing of those queries, etc.
      - name: persist_empty_tables
        kind: boolean
        value: false
        description: Whether the Target should create tables which have no records present in Remote.
      - name: max_batch_rows
        kind: integer
        value: 200000
        description: The maximum number of rows to buffer in memory before writing to the destination table in Postgres
      - name: max_buffer_size
        kind: integer
        value: 104857600
        description: "The maximum number of bytes to buffer in memory before writing to the destination table in Postgres. Default: 100MB in bytes"
      - name: batch_detection_threshold
        kind: integer
        description: How often, in rows received, to count the buffered rows and bytes to check if a flush is necessary. There's a slight performance penalty to checking the buffered records count or bytesize, so this controls how often this is polled in order to mitigate the penalty. This value is usually not necessary to set as the default is dynamically adjusted to check reasonably often.
      - name: state_support
        kind: boolean
        value: true
        description: Whether the Target should emit `STATE` messages to stdout for further consumption. In this mode, which is on by default, STATE messages are buffered in memory until all the records that occurred before them are flushed according to the batch flushing schedule the target is configured with.
      - name: add_upsert_indexes
        kind: boolean
        value: true
        description: Whether the Target should create column indexes on the important columns used during data loading. These indexes will make data loading slightly slower but the deduplication phase much faster. Defaults to on for better baseline performance.
      - name: before_run_sql
        description: Raw SQL statement(s) to execute as soon as the connection to Postgres is opened by the target. Useful for setup like `SET ROLE` or other connection state that is important.
      - name: after_run_sql
        description: Raw SQL statement(s) to execute as soon as the connection to Postgres is opened by the target. Useful for setup like `SET ROLE` or other connection state that is important.
    - name: transferwise
      docs: https://transferwise.github.io/pipelinewise/connectors/targets/postgres.html
      repo: https://github.com/transferwise/pipelinewise-target-postgres
      maintainer:
        name: Transferwise
        url: https://wise.com/
      maintenance_status: Active
      pip_url: pipelinewise-target-postgres
      settings_group_validation:
        - ['host', 'port', 'user', 'password', 'dbname', 'default_target_schema']
      settings:
        - name: host
          value: localhost
          description: PostgreSQL host
        - name: port
          kind: integer
          value: 5432
          description: PostgreSQL port
        - name: user
          description: PostgreSQL user
        - name: password
          kind: password
          description: PostgreSQL password
        - name: dbname
          description: PostgreSQL database name
        - name: ssl
          kind: boolean
          value: false
          value_post_processor: stringify
        - name: default_target_schema
          description: Name of the schema where the tables will be created. If `schema_mapping` is not defined then every stream sent by the tap is loaded into this schema.
        # Optional settings
        - name: batch_size_rows
          kind: integer
          value: 100000
          description: Maximum number of rows in each batch. At the end of each batch, the rows in the batch are loaded into Postgres.
        - name: flush_all_streams
          kind: boolean
          value: false
          description: "Flush and load every stream into Postgres when one batch is full. Warning: This may trigger the COPY command to use files with low number of records."
        - name: parallelism
          kind: integer
          value: 0
          description: The number of threads used to flush tables. 0 will create a thread for each stream, up to parallelism_max. -1 will create a thread for each CPU core. Any other positive number will create that number of threads, up to parallelism_max.
        - name: parallelism_max
          kind: integer
          value: 16
          description: Max number of parallel threads to use when flushing tables.
        - name: default_target_schema_select_permission
          description: Grant USAGE privilege on newly created schemas and grant SELECT privilege on newly created tables to a specific role or a list of roles. If `schema_mapping` is not defined then every stream sent by the tap is granted accordingly.
        - name: schema_mapping
          kind: object
          description: >
            Useful if you want to load multiple streams from one tap to multiple Postgres schemas.
            If the tap sends the `stream_id` in `<schema_name>-<table_name>` format then this option overwrites the `default_target_schema` value.
            Note, that using `schema_mapping` you can overwrite the `default_target_schema_select_permission` value to grant SELECT permissions to different groups per schemas or optionally you can create indices automatically for the replicated tables.
        - name: add_metadata_columns
          kind: boolean
          value: false
          description: Metadata columns add extra row level information about data ingestions, (i.e. when was the row read in source, when was inserted or deleted in postgres etc.) Metadata columns are creating automatically by adding extra columns to the tables with a column prefix `_SDC_`. The column names are following the stitch naming conventions documented at https://www.stitchdata.com/docs/data-structure/integration-schemas#sdc-columns. Enabling metadata columns will flag the deleted rows by setting the `_SDC_DELETED_AT` metadata column. Without the `add_metadata_columns` option the deleted rows from singer taps will not be recongisable in Postgres.
        - name: hard_delete
          kind: boolean
          value: false
          description: When `hard_delete` option is true then DELETE SQL commands will be performed in Postgres to delete rows in tables. It's achieved by continuously checking the `_SDC_DELETED_AT` metadata column sent by the singer tap. Due to deleting rows requires metadata columns, `hard_delete` option automatically enables the `add_metadata_columns` option as well.
        - name: data_flattening_max_level
          kind: integer
          value: 0
          description: Object type RECORD items from taps can be transformed to flattened columns by creating columns automatically. When value is 0 (default) then flattening functionality is turned off.
        - name: primary_key_required
          kind: boolean
          value: true
          description: Log based and Incremental replications on tables with no Primary Key cause duplicates when merging UPDATE events. When set to true, stop loading data if no Primary Key is defined.
        - name: validate_records
          kind: boolean
          value: false
          description: Validate every single record message to the corresponding JSON schema. This option is disabled by default and invalid RECORD messages will fail only at load time by Postgres. Enabling this option will detect invalid records earlier but could cause performance degradation.
        - name: temp_dir
          description: "(Default: platform-dependent) Directory of temporary CSV files with RECORD messages."
    - name: meltano
      repo: https://github.com/meltano/target-postgres
      maintainer:
        name: Meltano Community
      maintenance_status: Active
      pip_url: 'git+https://github.com/meltano/target-postgres.git'
      settings_group_validation:
        - ['url', 'schema']
        - ['user', 'password', 'host', 'port', 'dbname', 'schema']
      settings:
        - name: user
          value: warehouse
        - name: password
          kind: password
          value: warehouse
        - name: host
          value: localhost
        - name: port
          kind: integer
          value: 5502
        - name: dbname
          label: Database Name
          value: warehouse
        - name: url
          label: URL
          description: Lets you set `user`, `password`, `host`, `port`, and `dbname` in one go using a `postgresql://` URI. Takes precedence over the other settings when set.
        - name: schema
          schema_id: true
